{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import datasets, linear_model\n",
    "import sklearn.datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 3) (280,)\n",
      "(120, 3) (120,)\n",
      "length train X 280\n",
      "length test X 120\n",
      "length train y 280\n",
      "length test y 120\n"
     ]
    }
   ],
   "source": [
    "# Use pandas to read the CSV file as a dataframe\n",
    "df = pd.read_csv(\"moons400.csv\")\n",
    "# The y values are those labelled 'Class': extract their values\n",
    "y = df['Class'].values\n",
    "# using sklearn.model_selection.train_test_split to split up data into train and test sets split 70/30\n",
    "train_X, test_X, train_y, test_y = train_test_split(df, y, test_size=0.30)\n",
    "\n",
    "print(train_X.shape, train_y.shape)\n",
    "print(test_X.shape, test_y.shape)\n",
    "\n",
    "print(\"length train X\", len(train_X))\n",
    "print(\"length test X\", len(test_X))\n",
    "print(\"length train y\", len(train_y))\n",
    "print(\"length test y\", len(test_y))\n",
    "\n",
    "# The x train and test values are all other columns\n",
    "#print(train_X)\n",
    "del train_X['Class']    # drop the 'Class' column from the Train and test dataframe\n",
    "del test_X['Class']\n",
    "#print(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.687458510039\n"
     ]
    }
   ],
   "source": [
    "# fit a model\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(train_X, train_y)\n",
    "predictions = lm.predict(test_X)\n",
    "predictions[0:5]\n",
    "\n",
    "## The line / model\n",
    "plt.scatter(test_y, predictions)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "print (\"Score:\", model.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X): 280\n",
      "len(X[0]): 2\n",
      "len(X[:,0]): 280\n",
      "X: nsamples = 280 , nattribs = 2\n"
     ]
    }
   ],
   "source": [
    "train_X = train_X.as_matrix() # convert the remaining train columns to a numpy array\n",
    "test_X = test_X.as_matrix() # convert the remaining test columns to a numpy array\n",
    "\n",
    "# Some examples of working with the data, to look at rows/columns\n",
    "print (\"len(X):\", len(train_X))            # outer array: one per sample\n",
    "print (\"len(X[0]):\", len(train_X[0]))      # each inner array is the attributes of one sample\n",
    "print (\"len(X[:,0]):\", len(train_X[:,0]))  # select column 0 from array\n",
    "\n",
    "# np.shape returns all dimensions of the array\n",
    "(nsamples, nattribs) = np.shape(train_X)\n",
    "print (\"X: nsamples =\", nsamples, \", nattribs =\", nattribs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasubset_x: dsamples = 1 , dattribs = 2\n",
      "datasubset_x: [[ 1.66230734 -0.16230399]]\n"
     ]
    }
   ],
   "source": [
    "#Testing with just one epoch for train X\n",
    "datasubset_x = train_X[0:1]\n",
    "(dsamples, dattribs) = np.shape(datasubset_x)\n",
    "print(\"datasubset_x: dsamples =\", dsamples, \", dattribs =\", dattribs)\n",
    "print(\"datasubset_x:\",datasubset_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasubset_y:  [1]\n"
     ]
    }
   ],
   "source": [
    "#Testing with just one epoch for train y\n",
    "datasubset_y = train_y[0:1]\n",
    "print(\"datasubset_y: \",datasubset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.324253148611\n",
      "[[0.16251229711029291, 0.41582940800421264], [0.99009917240031153, 0.87745298975257635]]\n"
     ]
    }
   ],
   "source": [
    "#layer 1 weights\n",
    "print(np.random.random(1)[0])\n",
    "#W11_1 = -0.1\n",
    "#W12_1 = -0.1\n",
    "#W21_1 = -0.1\n",
    "#W22_1 = -0.1\n",
    "# initially assign the weights randomly \n",
    "W11_1 = np.random.random(1)[0]\n",
    "W12_1 = np.random.random(1)[0]\n",
    "W21_1 = np.random.random(1)[0]\n",
    "W22_1 = np.random.random(1)[0]\n",
    "\n",
    "#layer 1 bias\n",
    "#bias1_1 = 1\n",
    "#bias2_1 = 0.9\n",
    "bias1_1 = np.random.random(1)[0]\n",
    "bias2_1 = np.random.random(1)[0]\n",
    "\n",
    "#layer 2 weights\n",
    "#W11_2 = 0.1\n",
    "#W12_2 = 0.1\n",
    "W11_2 =  np.random.random(1)[0]\n",
    "W12_2 =  np.random.random(1)[0]\n",
    "#layer 2 bias\n",
    "#b_2 = 0.5\n",
    "bias_2 = np.random.random(1)[0]\n",
    "\n",
    "weights1 = [[W11_1,W12_1],[W21_1,W22_1]]\n",
    "print(weights1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer 1 [[ 0.44347745  0.10584129]\n",
      " [ 1.81918118  0.03091795]]\n"
     ]
    }
   ],
   "source": [
    "hidden1 = weights1 * epoch1_x + bias1_1 * 1\n",
    "print(\"Hidden Layer 1\", hidden1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1_2:  0.375986678579\n",
      "a1_2exp:  -0.456427731955\n",
      "a2_2:  1.54633199221\n",
      "a2_2exp:  -3.69422012926\n",
      "a1_3:  -2.65182433236\n",
      "a1_3exp:  0.929477560735\n"
     ]
    }
   ],
   "source": [
    "# a1_2 = f(w11_1*x1 + w12_1*x2 +b1_1 )\n",
    "#print(datasubset_x[0,0])\n",
    "\n",
    "# forward propagation\n",
    "\n",
    "a1_2 = (W11_1 * datasubset_x[0,0] + W12_1 * datasubset_x[0,1] + bias1_1 * 1)\n",
    "print(\"a1_2: \",a1_2)\n",
    "    \n",
    "a1_2 = 1/1 - np.exp(a1_2)\n",
    "print(\"a1_2exp: \",a1_2)\n",
    "\n",
    "a2_2 = (W21_1 * datasubset_x[0,0] + W22_1 * datasubset_x[0,1] + bias2_1 * 1)\n",
    "print(\"a2_2: \",a2_2)\n",
    "a2_2 = 1/1 - np.exp(a2_2)\n",
    "print(\"a2_2exp: \",a2_2)\n",
    "\n",
    "\n",
    "a1_3 = (W11_2 * a1_2 + W12_2 * a2_2 + bias_2 * 1 )\n",
    "print(\"a1_3: \",a1_3)\n",
    "#hW,b(X) = a1_3\n",
    "a1_3 = 1/1 - np.exp(a1_3)\n",
    "print(\"a1_3exp: \",a1_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a1_3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-185574ce66fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# sum of squared errors of prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0msse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasubset_y\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0ma1_3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SSE: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'a1_3' is not defined"
     ]
    }
   ],
   "source": [
    "a1_3 = activation()\n",
    "\n",
    "# Calculate the Total Error SSE = âˆ‘ 1/2(Y-YP)^2 \n",
    "#E_total = 1/2(target_01 - out_01)^2 \n",
    "\n",
    "# sum of squared errors of prediction\n",
    "sse = 1/2 * np.power((datasubset_y - a1_3), 2)\n",
    "print(\"SSE: \",sse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The Backwards back propagation\n",
    "\n",
    "# The goal with backpropagation is to update each of the weights in the network so that \n",
    "# they cause the actual output to be closer the target output, thereby minimizing the error \n",
    "# for each output neuron and the network as a whole.\n",
    "\n",
    "#Consider W11_2. We want to know how much a change in W11_2 affects the total error, \n",
    "#aka the partial derivative of a1_3 with respect to W11_2 or the gradient with respect to W11_2\n",
    "\n",
    "#First, how much does the total error change with respect to the output?\n",
    "#E_total = 1/2(target_01 - out_01)^2 + 1/2(target_02 - out_02)^2 \n",
    "print(\"SSE: \",sse)\n",
    "\n",
    "# The partial derivitive of the total error with respect to the output a1_3\n",
    "# âˆ‚SSE/âˆ‚a1_3 = 2 * 1/2(target- a1_3)^2-1 * -1 + 0 \n",
    "derivitive_a1_3 = 2 * 1/2 * np.power((datasubset_y - a1_3), 2-1) * -1 + 0\n",
    "print(\"derivitive_a1_3: \",derivitive_a1_3)\n",
    "\n",
    "## results in same output as above\n",
    "pd_sse_a1_3 = -(datasubset_y - a1_3)\n",
    "print(\"Partial derivitive of total error with respect to the output of a1_3: \",pd_sse_a1_3)\n",
    "\n",
    "#The partial derivative of the logistic function is the output multiplied by 1 minus the output:\n",
    "# partial derivitive of output a1_3 with respect to the net a1_3\n",
    "# out_o1 (1 - out_01)\n",
    "# a1_3 (1- a1_3)\n",
    "pd_a1_3 = a1_3 * (1 - a1_3)\n",
    "print(\"partial_derivitive_output a1_3: \",pd_a1_3)\n",
    "\n",
    "\n",
    "# âˆ‚SSE / âˆ‚a1_3 = sse(1 - sse)\n",
    "derivitive_sse = sse * (1 - sse) \n",
    "\n",
    "print(\"derivitive_sse: \",derivitive_sse)\n",
    "\n",
    "# How much does the total net input of a1_3 change with respect to W11_2\n",
    "# âˆ‚a1_3/âˆ‚W11_2 = 1 * a1_2 * W11_2^(1-1) + 0 + 0\n",
    "pd_a1_2 = 1 * a1_2 * np.power(W11_2,(1-1)) + 0 + 0\n",
    "print(\"Partial derivitive of a1_2 with respect to w11_2: \",pd_a1_2)\n",
    "\n",
    "# putting it all together\n",
    "# âˆ‚SSE/âˆ‚W11_2 = âˆ‚SSE / âˆ‚a1_3 * âˆ‚a1_3/âˆ‚net_a1_3 * âˆ‚net_a1_3/âˆ‚W11_2\n",
    "pd_sse_w11_2 = pd_sse_a1_3 * pd_a1_3 * pd_a1_2\n",
    "print(\"Partial derivitive of total SSE with respect to w11_2: \",pd_sse_w11_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#delta rule\n",
    "#delta_o1 = -(target_{o1} - out_{o1}) * out_{o1}(1 - out_{o1})\n",
    "\n",
    "#partial E_total\\partial w_5 = delta_o1*out_h1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
