{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import sklearn\n",
    "from sklearn import datasets, linear_model\n",
    "import sklearn.datasets\n",
    "from sklearn import preprocessing\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "#from mnist import MNIST\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the weights for the network based on the input layers, the number of hidden layers, the number of output layers\n",
    "#reference for above https://www.coursera.org/learn/deep-neural-network/lecture/RwqYe/weight-initialization-for-deep-networks\n",
    "def initialise_input_weights(n_inputs, n_hidden_inputs):\n",
    " hidden_layer_weights = list()\n",
    " for i in range(n_hidden_inputs):\n",
    "  weight = np.random.randn(n_inputs)*np.sqrt(1/(n_inputs)**(n_hidden_inputs-1))\n",
    "  hidden_layer_weights.append(weight)\n",
    "   \n",
    " input_weights = np.array([hidden_layer_weights], dtype=np.float64)\n",
    " input_weights = np.reshape(input_weights, (n_inputs, n_hidden_inputs))\n",
    " return input_weights; \n",
    "\n",
    "def initialise_output_weights(n_hidden_inputs,n_outputs):\n",
    " output_layer_weights = list()\n",
    " for i in range(n_hidden_inputs):\n",
    "  weight = np.random.randn(n_outputs)*np.sqrt(1/(n_outputs)**(n_hidden_inputs-1))\n",
    "  output_layer_weights.append(weight) \n",
    "   \n",
    " output_weights = np.array(output_layer_weights, dtype=np.float64)\n",
    " #if n_outputs == 1:\n",
    "  #output_weights = np.array([output_layer_weights])\n",
    " #elif n_outputs > 1:\n",
    "  #output_weights = np.array([output_layer_weights])  \n",
    "  #output_weights = np.reshape(output_weights, (n_hidden_inputs,n_outputs))   \n",
    "\n",
    " return output_weights;\n",
    "\n",
    "#initialise the bias for the network based on the number of hidden layers and the output layer bias\n",
    "def initialise_bias(n_hidden_layer):\n",
    " hidden_layer_bias = list()    \n",
    " for i in range(n_hidden_layer):\n",
    "  bias = np.random.random(1)[0]\n",
    "  hidden_layer_bias.append(bias)\n",
    " \n",
    " output_layer_bias = [np.random.random(1)[0]]\n",
    " network_bias = np.array([hidden_layer_bias,output_layer_bias],dtype=np.float64)\n",
    " return network_bias;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Weights:  [[-0.92626096  0.14734553]\n",
      " [ 1.5627489   0.62405363]]\n",
      "Output Weights:  [[ 0.35740898]\n",
      " [-0.03535481]]\n",
      "Bias: [[ 0.93763224]\n",
      " [ 0.62218154]]\n"
     ]
    }
   ],
   "source": [
    "# Testing weight intialisation\n",
    "n_hidden_layers = 1\n",
    "n_hidden_inputs = 2\n",
    "n_i_inputs = 2\n",
    "n_outputs = 1\n",
    "\n",
    "input_weights = initialise_input_weights(n_i_inputs, n_hidden_inputs)\n",
    "print(\"Input Weights: \",input_weights)\n",
    "weights = initialise_output_weights(n_hidden_inputs, n_outputs)\n",
    "print(\"Output Weights: \",weights)\n",
    "\n",
    "bias = initialise_bias(n_hidden_layers)\n",
    "print(\"Bias:\", bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Forward Propagation\n",
    "\n",
    "# Sigmoid function\n",
    "# g(z) = 1/ 1 + e^-z\n",
    "def sigmoid(z):\n",
    " g = 1/(1 + np.exp(-z))\n",
    " return g;\n",
    "\n",
    "def forward_activation(inputs, input_weights, output_weights, bias):\n",
    "    hidden_output_activation = get_hidden_activation(inputs, input_weights, bias[0])\n",
    "    output_activation = get_output_activation(hidden_output_activation, output_weights, bias[1])\n",
    "    \n",
    "    print(\"hidden_output_activation\", hidden_output_activation)\n",
    "    print(\"output_activation\", output_activation)\n",
    "    return hidden_output_activation, output_activation\n",
    "\n",
    "def get_hidden_activation(inputs, input_weights, bias):\n",
    "    hidden_net = 0\n",
    "    #hidden_output_list = list()\n",
    "    for i in range(len(input_weights)):\n",
    "        hidden_net += (input_weights[i] * inputs[i]) + bias * 1\n",
    "        \n",
    "    sigmoid_out = sigmoid(hidden_net)\n",
    "    #hidden_output_list.append(sigmoid_out)\n",
    "    \n",
    "    #hidden_output_activation = np.array(hidden_output_list, dtype=np.float64)\n",
    "    hidden_output_activation = np.array(sigmoid_out, dtype=np.float64)\n",
    "    return hidden_output_activation;\n",
    "\n",
    "def get_output_activation(hidden_output_activation, output_weights, bias):\n",
    "    out_net = 0\n",
    "    output_list = list()\n",
    "    for i in range(len(output_weights)):\n",
    "        out_net += (output_weights[i] * hidden_output_activation[i]) + bias * 1\n",
    "    \n",
    "    sigmoid_out = sigmoid(out_net)\n",
    "    output_activation = np.array(sigmoid_out, dtype=np.float64)\n",
    "    return output_activation;\n",
    "        \n",
    "def get_total_error(targets, output_activation):\n",
    "    total_error = 0\n",
    "    \n",
    "    for i in range(len(output_activation)):\n",
    "        error = targets - output_activation[i]\n",
    "        total_error += 1/2 * np.power(error, 2)\n",
    "    return total_error;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X): 280\n",
      "len(X[0]): 2\n",
      "len(X[:,0]): 280\n",
      "X: nsamples = 280 , nattribs = 2\n",
      "input_weights [[ 0.13899265  0.99674632]\n",
      " [-0.455725   -0.22486462]]\n",
      "output_weights [[ 0.78006857]\n",
      " [ 0.95751527]]\n",
      "bias  [ 0.35750022] [ 0.13229714]\n"
     ]
    }
   ],
   "source": [
    "# Setup Test data required for training\n",
    "\n",
    "# Use pandas to read the CSV file as a dataframe\n",
    "df = pd.read_csv(\"moons400.csv\")\n",
    "# The y values are those labelled 'Class': extract their values\n",
    "y = df['Class'].values\n",
    "# using sklearn.model_selection.train_test_split to split up data into train and test sets split 70/30\n",
    "train_X, test_X, train_y, test_y = train_test_split(df, y, test_size=0.30)\n",
    "\n",
    "del train_X['Class']    # drop the 'Class' column from the Train and test dataframe\n",
    "del test_X['Class']\n",
    "\n",
    "train_X = train_X.as_matrix() # convert the remaining train columns to a numpy array\n",
    "test_X = test_X.as_matrix() # convert the remaining test columns to a numpy array\n",
    "\n",
    "#print(train_y)\n",
    "\n",
    "# Some examples of working with the data, to look at rows/columns\n",
    "print (\"len(X):\", len(train_X))            # outer array: one per sample\n",
    "print (\"len(X[0]):\", len(train_X[0]))      # each inner array is the attributes of one sample\n",
    "print (\"len(X[:,0]):\", len(train_X[:,0]))  # select column 0 from array\n",
    "\n",
    "inputs = preprocessing.normalize(train_X) # normalise the input data\n",
    "# np.shape returns all dimensions of the input array\n",
    "(nsamples, nattribs) = np.shape(inputs)\n",
    "print (\"X: nsamples =\", nsamples, \", nattribs =\", nattribs)\n",
    "# the actual labeled target values\n",
    "targets = train_y\n",
    "\n",
    "# initialise neural network structure\n",
    "n_i_inputs = nattribs # number of attributes of inputs\n",
    "n_hidden_inputs = 2 # number of hidden input nodes\n",
    "n_hidden_layers = 1 # number of hidden layers\n",
    "n_outputs = 1 # number of output nodes\n",
    "\n",
    "# initialise weights\n",
    "input_weights = initialise_input_weights(n_i_inputs, n_hidden_inputs)\n",
    "output_weights = initialise_output_weights(n_hidden_inputs, n_outputs)\n",
    "bias = initialise_bias(n_hidden_layers)\n",
    "\n",
    "print(\"input_weights\", input_weights)\n",
    "print(\"output_weights\", output_weights)\n",
    "print(\"bias \",bias[0], bias[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_output_activation [ 0.6120145   0.81587719]\n",
      "output_activation [ 0.82101251]\n",
      "Total Error  [ 49.42686453]\n"
     ]
    }
   ],
   "source": [
    "# Test Forward Propagation\n",
    "hidden_output_activation, output_activation = forward_activation(inputs, input_weights, output_weights, bias)\n",
    "total_error = get_total_error(output_activation, targets)\n",
    "\n",
    "#print(\"Net inputs\", hidden_net)\n",
    "#print(\"Hidden output_activation\", hidden_output_activation)  \n",
    "#print(\"Net outputs\", out_net)\n",
    "#print(\"Output activation\", output_activation)  \n",
    "\n",
    "#print(\"targets \", targets) \n",
    "print(\"Total Error \",total_error)\n",
    "#epoch_list = list()\n",
    "#epoch_list.append(total_error)\n",
    "#print(epoch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back Propagation\n",
    "\n",
    "# The partial derivitive of the total error with respect to the output a1_3/output_activation \n",
    "# ∂Etotal/∂outo1 = 2 * 1/2(target- output_activation)^2-1 * -1 + 0 \n",
    "# outo1= output_activation, Etotal = sse_1\n",
    "# pd = Partial Derivitive, wrt= with respect to\n",
    "def calc_pd_total_error_wrt_output_activation(target, output):\n",
    "    pd_total_error_list = list()\n",
    "    for i in range(len(target)):\n",
    "        error = target[i] - output\n",
    "        pd_total_error = 2 * 1/2 * np.power((error), 2-1) * -1 + 0\n",
    "        pd_total_error_list.append(pd_total_error)\n",
    "      \n",
    "    pd_total_error_wrt_output_activation = np.array(pd_total_error_list, dtype=np.float64)\n",
    "    return pd_total_error_wrt_output_activation;\n",
    "\n",
    "# The partial derivitive of the total error with respect to the output a1_3/output_activation \n",
    "# ∂outo1/∂neto1 = output_activation(1 - output_activation) \n",
    "\n",
    "def calc_pd_output_activation_wrt_net_input(output):\n",
    "    pd_output_activation_wrt_net_input = output * (1 - output) \n",
    "    print(\"partial_derivitive_output with respect to net input: \",pd_output_activation_wrt_net_input)\n",
    "    return pd_output_activation_wrt_net_input;\n",
    "\n",
    "\n",
    "#The partial derivitive of net output with respect to weight i:\n",
    "# outputs: out_h1 & out_h2 weights w11_2, w12_2\n",
    "def calc_pd_net_output_wrt_weight(layer_output, output_weights):\n",
    "    print(\"Shape of layer_output\", np.shape(layer_output))\n",
    "    print(\"Shape of Output weights\", np.shape(output_weights))\n",
    "    print(layer_output)\n",
    "    print(output_weights)\n",
    "    pd_net_output_wrt_weight =  1 * layer_output * np.power(output_weights,(1-1)) + 0 + 0\n",
    "    print(\"Partial derivitive of net output with respect to weight: \",pd_net_output_wrt_weight)\n",
    "    return pd_net_output_wrt_weight;\n",
    "    \n",
    "\n",
    "# The partial derivitive of Etotal with respect to W5\n",
    "# this is for a single weight W5, same process also has to be done for W6\n",
    "# ∂Etotal/∂W11_2 = ∂Etotal/∂outo1 * ∂outo1/∂neto1 * ∂neto1/∂w11_2 \n",
    "def calc_pd_total_error_wrt_weight(pd_total_error_wrt_output_activation, pd_output_activation_wrt_net_input, pd_net_output_wrt_weight ):\n",
    "    pd_total_error_wrt_weight = pd_total_error_wrt_output_activation * pd_output_activation_wrt_net_input * pd_net_output_wrt_weight\n",
    "    print(\"Partial derivitive of Total Error with respect to weight: \",pd_total_error_wrt_weight)\n",
    "    return pd_total_error_wrt_weight;\n",
    "\n",
    "# Calculate the adjusted input/output weights\n",
    "# ∂Etotal/∂W11_2 = δ_o1 out_h1\n",
    "# Wi^ = Wi - α * ∂Etotal/∂Wi\n",
    "def adjust_weight(weight, pd_total_error_wrt_weight):\n",
    "    adjusted_weight = weight - alpha * pd_total_error_wrt_weight\n",
    "    return adjusted_weight;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partial_derivitive_output with respect to net input:  [ 0.14695097]\n",
      "Shape of layer_output (2,)\n",
      "Shape of Output weights (2, 1)\n",
      "[ 0.6120145   0.81587719]\n",
      "[[ 0.78006857]\n",
      " [ 0.95751527]]\n",
      "Partial derivitive of net output with respect to weight:  [[ 0.6120145   0.81587719]\n",
      " [ 0.6120145   0.81587719]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (280,1) (2,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-140-d794ed708596>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mpd_net_output_wrt_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalc_pd_net_output_wrt_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_output_activation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mpd_total_error_wrt_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalc_pd_total_error_wrt_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd_total_error_wrt_output_activation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd_output_activation_wrt_net_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd_net_output_wrt_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0madjusted_output_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madjust_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd_total_error_wrt_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-139-44eddd20fa3c>\u001b[0m in \u001b[0;36mcalc_pd_total_error_wrt_weight\u001b[1;34m(pd_total_error_wrt_output_activation, pd_output_activation_wrt_net_input, pd_net_output_wrt_weight)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# ∂Etotal/∂W11_2 = ∂Etotal/∂outo1 * ∂outo1/∂neto1 * ∂neto1/∂w11_2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalc_pd_total_error_wrt_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd_total_error_wrt_output_activation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd_output_activation_wrt_net_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd_net_output_wrt_weight\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mpd_total_error_wrt_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd_total_error_wrt_output_activation\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpd_output_activation_wrt_net_input\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpd_net_output_wrt_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Partial derivitive of Total Error with respect to weight: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpd_total_error_wrt_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd_total_error_wrt_weight\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (280,1) (2,2) "
     ]
    }
   ],
   "source": [
    "# Test Back Propagation\n",
    "pd_total_error_wrt_output_activation = calc_pd_total_error_wrt_output_activation(targets, output_activation)\n",
    "\n",
    "pd_output_activation_wrt_net_input = calc_pd_output_activation_wrt_net_input(output_activation)\n",
    "    \n",
    "pd_net_output_wrt_weight = calc_pd_net_output_wrt_weight(hidden_output_activation, output_weights)\n",
    "    \n",
    "pd_total_error_wrt_weight = calc_pd_total_error_wrt_weight(pd_total_error_wrt_output_activation, pd_output_activation_wrt_net_input, pd_net_output_wrt_weight) \n",
    "\n",
    "adjusted_output_weight = adjust_weight(output_weights, pd_total_error_wrt_weight)\n",
    "\n",
    "print(\"Partial derivitive of total error with respect to the output: \",pd_total_error_wrt_output_activation)\n",
    "print(\"Adjusted Output Weights: \",adjusted_output_weight)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partial_derivitive_output with respect to net input:  [ 0.23745275  0.1502216 ]\n",
      "Shape of layer_output (2,)\n",
      "Shape of Output weights (2, 2)\n",
      "[ 0.6120145   0.81587719]\n",
      "[[ 0.13899265  0.99674632]\n",
      " [-0.455725   -0.22486462]]\n",
      "Partial derivitive of net output with respect to weight:  [[ 0.6120145   0.81587719]\n",
      " [ 0.6120145   0.81587719]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (280,2) (2,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-a9fdf562b676>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mpd_hidden_net_wrt_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalc_pd_net_output_wrt_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_output_activation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mpd_total_error_wrt_input_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalc_pd_total_error_wrt_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd_total_error_wrt_hidden_activation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd_hidden_activation_wrt_net_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd_hidden_net_wrt_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0madjusted_input_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madjust_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd_total_error_wrt_input_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-139-44eddd20fa3c>\u001b[0m in \u001b[0;36mcalc_pd_total_error_wrt_weight\u001b[1;34m(pd_total_error_wrt_output_activation, pd_output_activation_wrt_net_input, pd_net_output_wrt_weight)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# ∂Etotal/∂W11_2 = ∂Etotal/∂outo1 * ∂outo1/∂neto1 * ∂neto1/∂w11_2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalc_pd_total_error_wrt_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd_total_error_wrt_output_activation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd_output_activation_wrt_net_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd_net_output_wrt_weight\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mpd_total_error_wrt_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd_total_error_wrt_output_activation\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpd_output_activation_wrt_net_input\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpd_net_output_wrt_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Partial derivitive of Total Error with respect to weight: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpd_total_error_wrt_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd_total_error_wrt_weight\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (280,2) (2,2) "
     ]
    }
   ],
   "source": [
    "# hidden layer weights update\n",
    "\n",
    "pd_total_error_wrt_hidden_activation = calc_pd_total_error_wrt_output_activation(targets, hidden_output_activation)\n",
    "\n",
    "pd_hidden_activation_wrt_net_input = calc_pd_output_activation_wrt_net_input(hidden_output_activation)\n",
    "    \n",
    "pd_hidden_net_wrt_weight = calc_pd_net_output_wrt_weight(hidden_output_activation, input_weights)\n",
    "    \n",
    "pd_total_error_wrt_input_weight = calc_pd_total_error_wrt_weight(pd_total_error_wrt_hidden_activation, pd_hidden_activation_wrt_net_input, pd_hidden_net_wrt_weight) \n",
    "\n",
    "adjusted_input_weight = adjust_weight(input_weights, pd_total_error_wrt_input_weight)\n",
    "\n",
    "print(\"Adjusted Input Weights: \",adjusted_input_weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
