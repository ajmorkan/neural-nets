{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X): 400\n",
      "len(X[0]): 2\n",
      "len(X[:,0]): 400\n",
      "X: nsamples = 400 , nattribs = 2\n"
     ]
    }
   ],
   "source": [
    "# Use pandas to read the CSV file as a dataframe\n",
    "df = pd.read_csv(\"moons400.csv\")\n",
    "# The y values are those labelled 'Class': extract their values\n",
    "y = df['Class'].values\n",
    "\n",
    "# The x values are all other columns\n",
    "del df['Class']    # drop the 'Class' column from the dataframe\n",
    "X = df.as_matrix() # convert the remaining columns to a numpy array\n",
    "# Some examples of working with the data, to look at rows/columns\n",
    "print (\"len(X):\", len(X))            # outer array: one per sample\n",
    "print (\"len(X[0]):\", len(X[0]))      # each inner array is the attributes of one sample\n",
    "print (\"len(X[:,0]):\", len(X[:,0]))  # select column 0 from array\n",
    "\n",
    "# np.shape returns all dimensions of the array\n",
    "(nsamples, nattribs) = np.shape(X)\n",
    "print (\"X: nsamples =\", nsamples, \", nattribs =\", nattribs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasubset: dsamples = 1 , dattribs = 2\n",
      "[[ 2.07106946  0.41152931]]\n"
     ]
    }
   ],
   "source": [
    "datasubset_x = X[0:1]\n",
    "(dsamples, dattribs) = np.shape(datasubset_x)\n",
    "print(\"datasubset: dsamples =\", dsamples, \", dattribs =\", dattribs)\n",
    "print(datasubset_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "datasubset_y = y[0:1]\n",
    "print(datasubset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#layer 1 weights\n",
    "W11_1 = -0.1\n",
    "W12_1 = -0.1\n",
    "W21_1 = -0.1\n",
    "W22_1 = -0.1\n",
    "#layer 1 bias\n",
    "b1_1 = 1\n",
    "b2_1 = 0.9\n",
    "#layer 2 weights\n",
    "W11_2 = 0.1\n",
    "W12_2 = 0.1\n",
    "#layer 2 bias\n",
    "b_2 = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1_2:  0.751740122949\n",
      "a1_2exp:  -1.12068706395\n",
      "a2_2:  0.651740122949\n",
      "a2_2exp:  -0.918877007408\n",
      "a1_3:  0.296043592864\n",
      "a1_3exp:  -0.344528767414\n"
     ]
    }
   ],
   "source": [
    "# a1_2 = f(w11_1*x1 + w12_1*x2 +b1_1 )\n",
    "#print(datasubset_x[0,0])\n",
    "\n",
    "a1_2 = (W11_1 * datasubset_x[0,0] + W12_1 * datasubset_x[0,1] + b1_1 * 1)\n",
    "print(\"a1_2: \",a1_2)\n",
    "\n",
    "a1_2 = 1/1 - np.exp(a1_2)\n",
    "print(\"a1_2exp: \",a1_2)\n",
    "\n",
    "a2_2 = (W21_1 * datasubset_x[0,0] + W22_1 * datasubset_x[0,1] + b2_1 * 1)\n",
    "print(\"a2_2: \",a2_2)\n",
    "a2_2 = 1/1 - np.exp(a2_2)\n",
    "print(\"a2_2exp: \",a2_2)\n",
    "\n",
    "\n",
    "a1_3 = (W11_2 * a1_2 + W12_2 * a2_2 + b_2 * 1 )\n",
    "print(\"a1_3: \",a1_3)\n",
    "#hW,b(X) = a1_3\n",
    "a1_3 = 1/1 - np.exp(a1_3)\n",
    "print(\"a1_3exp: \",a1_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE:  [ 0.9038788]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Total Error SSE = ∑ 1/2(Y-YP)^2 \n",
    "#E_total = 1/2(target_01 - out_01)^2 \n",
    "\n",
    "# sum of squared errors of prediction\n",
    "sse = 1/2 * np.power((datasubset_y - a1_3), 2)\n",
    "print(\"SSE: \",sse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE:  [ 0.9038788]\n",
      "derivitive_a1_3:  [-1.34452877]\n",
      "Partial derivitive of total error with respect to the output of a1_3:  [-1.34452877]\n",
      "partial_derivitive_output a1_3:  -0.46322883899\n",
      "derivitive_sse:  [ 0.08688191]\n",
      "Partial derivitive of a1_2 with respect to w11_2:  -1.12068706395\n",
      "Partial derivitive of total SSE with respect to w11_2:  [-0.69799136]\n"
     ]
    }
   ],
   "source": [
    "#The Backwards back propagation\n",
    "\n",
    "# The goal with backpropagation is to update each of the weights in the network so that \n",
    "# they cause the actual output to be closer the target output, thereby minimizing the error \n",
    "# for each output neuron and the network as a whole.\n",
    "\n",
    "#Consider W11_2. We want to know how much a change in W11_2 affects the total error, \n",
    "#aka the partial derivative of a1_3 with respect to W11_2 or the gradient with respect to W11_2\n",
    "\n",
    "#First, how much does the total error change with respect to the output?\n",
    "#E_total = 1/2(target_01 - out_01)^2 + 1/2(target_02 - out_02)^2 \n",
    "print(\"SSE: \",sse)\n",
    "\n",
    "# The partial derivitive of the total error with respect to the output a1_3\n",
    "# ∂SSE/∂a1_3 = 2 * 1/2(target- a1_3)^2-1 * -1 + 0 \n",
    "derivitive_a1_3 = 2 * 1/2 * np.power((datasubset_y - a1_3), 2-1) * -1 + 0\n",
    "print(\"derivitive_a1_3: \",derivitive_a1_3)\n",
    "\n",
    "## results in same output as above\n",
    "pd_sse_a1_3 = -(datasubset_y - a1_3)\n",
    "print(\"Partial derivitive of total error with respect to the output of a1_3: \",pd_sse_a1_3)\n",
    "\n",
    "#The partial derivative of the logistic function is the output multiplied by 1 minus the output:\n",
    "# partial derivitive of output a1_3 with respect to the net a1_3\n",
    "# out_o1 (1 - out_01)\n",
    "# a1_3 (1- a1_3)\n",
    "pd_a1_3 = a1_3 * (1 - a1_3)\n",
    "print(\"partial_derivitive_output a1_3: \",pd_a1_3)\n",
    "\n",
    "\n",
    "# ∂SSE / ∂a1_3 = sse(1 - sse)\n",
    "derivitive_sse = sse * (1 - sse) \n",
    "\n",
    "print(\"derivitive_sse: \",derivitive_sse)\n",
    "\n",
    "# How much does the total net input of a1_3 change with respect to W11_2\n",
    "# ∂a1_3/∂W11_2 = 1 * a1_2 * W11_2^(1-1) + 0 + 0\n",
    "pd_a1_2 = 1 * a1_2 * np.power(W11_2,(1-1)) + 0 + 0\n",
    "print(\"Partial derivitive of a1_2 with respect to w11_2: \",pd_a1_2)\n",
    "\n",
    "# putting it all together\n",
    "# ∂SSE/∂W11_2 = ∂SSE / ∂a1_3 * ∂a1_3/∂net_a1_3 * ∂net_a1_3/∂W11_2\n",
    "pd_sse_w11_2 = pd_sse_a1_3 * pd_a1_3 * pd_a1_2\n",
    "print(\"Partial derivitive of total SSE with respect to w11_2: \",pd_sse_w11_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#delta rule\n",
    "#delta_o1 = -(target_{o1} - out_{o1}) * out_{o1}(1 - out_{o1})\n",
    "\n",
    "#partial E_total\\partial w_5 = delta_o1*out_h1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
