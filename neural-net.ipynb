{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mnist import MNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X): 400\n",
      "len(X[0]): 3\n",
      "len(X[:,0]): 400\n",
      "X: nsamples = 400 , nattribs = 3\n",
      "(280, 3) (280,)\n",
      "(120, 3) (120,)\n",
      "length train X 280\n",
      "length test X 120\n",
      "length train y 280\n",
      "length test y 120\n",
      "train:  (280, 2) (280,)\n",
      "test:  (120, 2) (120,)\n"
     ]
    }
   ],
   "source": [
    "# set up training rate alpha\n",
    "alpha = 0.5\n",
    "\n",
    "# Use pandas to read the CSV file as a dataframe\n",
    "df = pd.read_csv(\"moons400.csv\")\n",
    "# The y values are those labelled 'Class': extract their values\n",
    "y = df['Class'].values\n",
    "\n",
    "# The x values are all other columns\n",
    "#del df['Class']    # drop the 'Class' column from the dataframe\n",
    "X = df.as_matrix() # convert the remaining columns to a numpy array\n",
    "# Some examples of working with the data, to look at rows/columns\n",
    "print (\"len(X):\", len(X))            # outer array: one per sample\n",
    "print (\"len(X[0]):\", len(X[0]))      # each inner array is the attributes of one sample\n",
    "print (\"len(X[:,0]):\", len(X[:,0]))  # select column 0 from array\n",
    "\n",
    "# np.shape returns all dimensions of the array\n",
    "(nsamples, nattribs) = np.shape(X)\n",
    "print (\"X: nsamples =\", nsamples, \", nattribs =\", nattribs)\n",
    "\n",
    "# using sklearn.model_selection.train_test_split to split up data into train and test sets split 70/30\n",
    "train_X, test_X, train_y, test_y = train_test_split(df, y, test_size=0.30)\n",
    "\n",
    "print(train_X.shape, train_y.shape)\n",
    "print(test_X.shape, test_y.shape)\n",
    "\n",
    "print(\"length train X\", len(train_X))\n",
    "print(\"length test X\", len(test_X))\n",
    "print(\"length train y\", len(train_y))\n",
    "print(\"length test y\", len(test_y))\n",
    "\n",
    "# The x train and test values are all other columns\n",
    "#print(train_X)\n",
    "del train_X['Class']    # drop the 'Class' column from the Train and test dataframe\n",
    "del test_X['Class']\n",
    "#print(test_X)\n",
    "\n",
    "print(\"train: \", train_X.shape, train_y.shape)\n",
    "print(\"test: \", test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasubset: dsamples = 280 , dattribs = 2\n"
     ]
    }
   ],
   "source": [
    "#datasubset_x = X[0:2]\n",
    "datasubset_x = train_X[0:2]\n",
    "datasubset_x = train_X\n",
    "(dsamples, dattribs) = np.shape(datasubset_x)\n",
    "print(\"datasubset: dsamples =\", dsamples, \", dattribs =\", dattribs)\n",
    "\n",
    "# print(datasubset_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale the inputs using normalization \n",
    "inputs = preprocessing.normalize(datasubset_x)\n",
    "# inputs = datasubset_x\n",
    "# inputs[0,0] = 0.05\n",
    "# inputs[0,1] = 0.1\n",
    "# print(inputs)\n",
    "inputs = np.array(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = y[0:20]\n",
    "target = train_y[0:2]\n",
    "target = train_y\n",
    "# target = 0.01\n",
    "#print(target)\n",
    "target = np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up training rate alpha\n",
    "alpha = 0.5\n",
    "\n",
    "# initialise the weights for the network based on the input layers, the number of hidden layers, the number of output layers\n",
    "def initialise_input_weights(n_inputs, n_hidden_inputs):\n",
    " hidden_layer_weights = list()\n",
    " for i in range(n_hidden_inputs):\n",
    "  for j in range(n_inputs):\n",
    "   weight = np.random.random(1)[0]\n",
    "   hidden_layer_weights.append(weight)\n",
    " \n",
    " input_weights = np.array([hidden_layer_weights])\n",
    " input_weights = np.reshape(input_weights, (n_inputs, n_hidden_inputs))\n",
    " return input_weights; \n",
    "\n",
    "def initialise_output_weights(n_hidden_inputs,n_outputs):\n",
    " output_layer_weights = list()\n",
    " for i in range(n_outputs):\n",
    "  for j in range(n_hidden_inputs):\n",
    "   weight = np.random.random(1)[0]\n",
    "   output_layer_weights.append(weight) \n",
    "  \n",
    " if n_outputs == 1:\n",
    "  output_weights = np.array([output_layer_weights])\n",
    " elif n_outputs > 1:\n",
    "  output_weights = np.array([output_layer_weights])  \n",
    "  output_weights = np.reshape(output_weights, (n_hidden_inputs,n_outputs))\n",
    " \n",
    " return output_weights;\n",
    "    \n",
    "#initialise the bias for the network based on the number of hidden layers and the output layer bias\n",
    "def initialise_bias(n_hidden_layer):\n",
    " hidden_layer_bias = list()    \n",
    " for i in range(n_hidden_layer):\n",
    "  bias = np.random.random(1)[0]\n",
    "  hidden_layer_bias.append(bias)\n",
    " \n",
    " output_layer_bias = [np.random.random(1)[0]]\n",
    " network_bias = [[hidden_layer_bias],[output_layer_bias]]\n",
    " return network_bias;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FORWARD PROPAGATION USING FUNCTIONS\n",
    "# do the above using a function\n",
    "# convert calculations to function for hidden layer\n",
    "def get_sigmoid_output(weights, input, bias):\n",
    "    hidden_layer = input * weights \n",
    "    hidden_layer = np.sum(hidden_layer, axis=1) + bias\n",
    "    hidden_layer = 1/(1+np.exp(-hidden_layer))\n",
    "    return hidden_layer;\n",
    "\n",
    "def get_output(sigmoid_out, weights, bias):\n",
    "    output = (sigmoid_out*weights)\n",
    "    output = 1/(1+np.exp(-(np.sum(output)+bias)))\n",
    "    return output;\n",
    "\n",
    "# get the error \n",
    "# error_o = (0.5*(target - output)**2)\n",
    "# print(error_o)\n",
    "\n",
    "#convert to a function\n",
    "# I think this needs to change to accept a numpy array as well\n",
    "# we should end up with a data frame we can plot against the number of executions\n",
    "def get_error(t, o):\n",
    "    error_o = (0.5*(t - o)**2)\n",
    "    return error_o;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FUNCTIONS FOR BACK PROPAGATION OF OUTPUT\n",
    "# calculate derivative of error at output layer\n",
    "\n",
    "# deriv_wrt_out = -(target - output)\n",
    "# change above to function\n",
    "def deltaErr_wrt_out(targ, outp):\n",
    "    result = -(targ - outp)\n",
    "    return result;  \n",
    "\n",
    "# calculate the derivation of the error output wrt the net\n",
    "# derivout_wrt_net = output*(1-output)\n",
    "# change above to function\n",
    "def deltaOut_wrt_net(outp):\n",
    "    result = outp*(1-outp)\n",
    "    return result;   \n",
    "\n",
    "# change above to function\n",
    "# calculate derivative of error wrt to output layer weight OLW_Deriv\n",
    "def deltaErr_ow(deriv_wrt_out, derivout_wrt_net, activation):\n",
    "    OLW_Deriv = deriv_wrt_out*derivout_wrt_net*activation\n",
    "   # print(OLW_Deriv)\n",
    "    return OLW_Deriv;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# FUNCTIONS FOR BACK PROPAGATION OF HIDDEN LAYER\n",
    "# calculate derivative of error at hidden layer\n",
    "\n",
    "# deriv_out_wrt_hL =  Weights2 * deriv_wrt_out *derivout_wrt_net\n",
    "# print (deriv_out_wrt_hL)\n",
    "# convert above to function\n",
    "def deltaOut_hL(deriv_wrt_out, derivout_wrt_net, weights):\n",
    "    deriv_out_wrt_hL = deriv_wrt_out *derivout_wrt_net *  weights\n",
    "    return deriv_out_wrt_hL;\n",
    "\n",
    "# deriv_out_wrt_nethL = activation*(1-activation)\n",
    "# convert above to function\n",
    "def deltaOut_netHL(activation):\n",
    "    activation = activation*(1-activation)\n",
    "    return activation;\n",
    "\n",
    "# deriv_wrt_wi = deriv_out_wrt_hL*deriv_out_wrt_nethL*Weights1\n",
    "# convert above to function\n",
    "def deltaErr_wi(deriv_out_wrt_hL, deriv_out_wrt_nethL, weights):\n",
    "    deriv_wrt_wi = deriv_out_wrt_hL*deriv_out_wrt_nethL*weights\n",
    "    return deriv_wrt_wi;\n",
    "\n",
    "# convert the above to a function\n",
    "def calc_adjusted_weights(W, deriv):\n",
    "    W = W - (alpha*deriv)\n",
    "    return W;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished after  6  error = 0.147181222277 target= 0 , output= 0.542551789743 input final= [ 0.99654419  0.08306432]\n"
     ]
    }
   ],
   "source": [
    "# use a loop to iterate through the dataset\n",
    "# and present records 1 by 1\n",
    "# for i in np.nditer(inputs, flags=['external_loop'], order='C'):\n",
    "#for i in range(len(inputs)):\n",
    "#    print (i)\n",
    "#    for t in range((target[i])):## this part is not working because it loops through the whole target array each time\n",
    "#        print(t)  ## not what we want\n",
    "\n",
    "#TRAIN MODEL\n",
    "\n",
    "threshold=1e-7\n",
    "maxrounds=5\n",
    "iter=0\n",
    "error = 99.0\n",
    "while abs(error) > threshold:\n",
    "    for i in range(len(inputs)):\n",
    "        \n",
    "        # START OF FORWARD PROPAGATION FUNCTION CALLS\n",
    "        # test get_sigmoid_output \n",
    "        hidden_layer = get_sigmoid_output(Weights1, inputs[i], bias_1)\n",
    "        #print (\"hidden_layer result:\", hidden_layer)\n",
    "\n",
    "        # test get_output\n",
    "        output = get_output(hidden_layer, Weights2, bias_2)\n",
    "        #print (\"output:\", output)\n",
    "\n",
    "        # call error function\n",
    "        error = get_error(target[i], output)\n",
    "       # print(\"error:\", error)\n",
    "\n",
    "        # END OF FORWARD PROPAGATION FUNCTION CALLS\n",
    "\n",
    "        # START OF BACK PROPAGATION FOR OUTPUT LAYER\n",
    "        #test function deltaErr_wrt_out\n",
    "        deltaErr_out = deltaErr_wrt_out(target[i], output)\n",
    "        # print(deltaErr_out)\n",
    "\n",
    "        #test function\n",
    "        deltaOut_net = deltaOut_wrt_net(output)\n",
    "        # print(deltaOut_net)\n",
    "\n",
    "        deltaErrtot_ow = deltaErr_ow(deltaErr_out, deltaOut_net, hidden_layer)\n",
    "        # print(deltaErrtot_ow)\n",
    "\n",
    "        # END OF BACK PROPAGATION FOR OUTPUT LAYER\n",
    "\n",
    "        # START BACK PROPAGATION OF HIDDEN LAYER\n",
    "        # calculate derivative of error at hidden layer\n",
    "\n",
    "        # test function deltaOut_hL\n",
    "        deltaErrOut_hL = deltaOut_hL(deltaErr_out, deltaOut_net, Weights2)\n",
    "        # print(deltaErrOut_hL)\n",
    "\n",
    "        #test function \n",
    "        deltaErrOut_netHL = deltaOut_netHL(hidden_layer)\n",
    "        # print(deltaErrOut_netHL)\n",
    "\n",
    "        deltaErrH_wi = deltaErr_wi(deltaErrOut_hL, deltaErrOut_netHL, Weights1)\n",
    "        # print(deltaErrH_wi)\n",
    "\n",
    "        # same calculation as above but with Weights matrix \n",
    "        # calculate adjusted weights using function\n",
    "        Weights2 = calc_adjusted_weights(Weights2, deltaErrtot_ow)\n",
    "        Weights1 = calc_adjusted_weights(Weights1, deltaErrH_wi)\n",
    "\n",
    "        # END OF BACK PROPAGATION OF HIDDEN LAYER\n",
    "\n",
    "    iter=iter+1\n",
    "    \n",
    "    if (iter > maxrounds):\n",
    "        break\n",
    "\n",
    "print (\"\\nFinished after \", iter, \" error =\", error, \"target=\", target[i], \", output=\", output, \"input final=\", inputs[i])    \n",
    "\n",
    "#print (\"Weights1 adjusted:\", Weights1)\n",
    "#print (\"Weights2 adjusted:\", Weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reference https://pypi.python.org/pypi/python-mnist\n",
    "# https://github.com/sorki/python-mnist/blob/master/mnist/loader.py\n",
    "# TRAIN MNIST DATA\n",
    "\n",
    "mndata = MNIST('./mnist')\n",
    "images, labels = mndata.load_training()\n",
    "\n",
    "processed_images = mndata.process_images_to_numpy(images)\n",
    "# print(processed_images[0:2])\n",
    "\n",
    "target = np.array(labels)\n",
    "# print(target[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up 2 lists to filter the MNIST data into\n",
    "# keeping only 0 and 6 to classify\n",
    "# TRAIN MNIST DATA\n",
    "\n",
    "filtered_labels = []\n",
    "filtered_images = []\n",
    "for i in range(len(target)):\n",
    "    if target[i]==0 or target[i]==6:\n",
    "        filtered_labels.append(target[i])\n",
    "        filtered_images.append(processed_images[i])\n",
    "        \n",
    "# remap the value 6 to 1, so classification is binary\n",
    "\n",
    "# print(filtered_labels[0:10])\n",
    "\n",
    "for i in range(len(filtered_labels)):\n",
    "    if filtered_labels[i]==6:\n",
    "        filtered_labels[i]=1\n",
    "\n",
    "# print(filtered_labels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert the lists to arrays\n",
    "# TRAIN MNIST DATA\n",
    "filtered_labels = np.array(filtered_labels)\n",
    "\n",
    "filtered_images = np.array(filtered_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST TEST DATA\n",
    "test_images, test_labels = mndata.load_testing()\n",
    "\n",
    "test_images = mndata.process_images_to_numpy(test_images)\n",
    "# print(processed_images[0:2])\n",
    "\n",
    "test_target = np.array(test_labels)\n",
    "\n",
    "# set up 2 lists to filter the MNIST data into\n",
    "# keeping only 0 and 6 to classify\n",
    "# TEST MNIST DATA\n",
    "\n",
    "filtered_test_labels = []\n",
    "filtered_test_images = []\n",
    "for i in range(len(target)):\n",
    "    if target[i]==0 or target[i]==6:\n",
    "        filtered_test_labels.append(target[i])\n",
    "        filtered_test_images.append(processed_images[i])\n",
    "        \n",
    "# remap the value 6 to 1, so classification is binary\n",
    "\n",
    "# print(filtered_labels[0:10])\n",
    "\n",
    "for i in range(len(filtered_test_labels)):\n",
    "    if filtered_test_labels[i]==6:\n",
    "        filtered_test_labels[i]=1\n",
    "        \n",
    "# convert the lists to arrays\n",
    "# TEST MNIST DATA\n",
    "filtered_test_labels = np.array(filtered_test_labels)\n",
    "\n",
    "filtered_test_images = np.array(filtered_test_images)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 1, 0, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(filtered_test_labels[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: samples = 11841 , attribs = 784\n",
      "Length of inputs 11841\n",
      "input Weights 784\n",
      "output Weights 1\n",
      "Network Bias 2\n"
     ]
    }
   ],
   "source": [
    "# set up weights and biases for MNIST data, get nattribs value\n",
    "# TRAIN MNIST DATA\n",
    "\n",
    "(train_samples, train_shape) = np.shape(filtered_images)\n",
    "print (\"train: samples =\", train_samples, \", attribs =\", train_shape)\n",
    "\n",
    "# Test weights and bias initialisation based on network inputs, hidden layers, and outputs\n",
    "# first line of moons.csv\n",
    "#input_X =[[2.07106946, 0.41152931]]\n",
    "\n",
    "#(nsamples, nattribs) = np.shape(input_X)\n",
    "n_inputs = train_shape\n",
    "n_hidden_layer = 1\n",
    "n_hidden_inputs = 2\n",
    "n_outputs = 1\n",
    "\n",
    "# normalise training data\n",
    "# rescale the inputs using normalization \n",
    "mnist_train = preprocessing.normalize(filtered_images)\n",
    "#print(\"normalised inputs\",inputs)\n",
    "\n",
    "input_weights = np.array(initialise_input_weights(n_inputs, n_hidden_inputs))\n",
    "output_weights = np.array(initialise_output_weights(n_hidden_inputs, n_outputs))\n",
    "#network_weights = initialise_weights(n_inputs, n_hidden_inputs, n_outputs)\n",
    "network_bias = np.array(initialise_bias(n_hidden_layer))\n",
    "\n",
    "print(\"Length of inputs\",len(filtered_images))\n",
    "#print(\"actual y\",input_y)\n",
    "print(\"input Weights\", len(input_weights))\n",
    "print(\"output Weights\", len(output_weights))\n",
    "print(\"Network Bias\", len(network_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "120\n",
      "input index:  [ 0.67691903  0.73605749]\n",
      "target index:  0\n",
      "input index:  [ 0.05456579 -0.99851018]\n",
      "target index:  1\n",
      "input index:  [ 0.30681998  0.95176757]\n",
      "target index:  1\n",
      "input index:  [-0.96609103  0.2582017 ]\n",
      "target index:  0\n",
      "input index:  [ 0.9581833  -0.28615512]\n",
      "target index:  1\n",
      "input index:  [ 0.98908998 -0.1473126 ]\n",
      "target index:  1\n",
      "input index:  [ 0.79322296 -0.60893131]\n",
      "target index:  1\n",
      "input index:  [ 0.99547416 -0.09503259]\n",
      "target index:  1\n",
      "input index:  [ 0.99970219  0.02440335]\n",
      "target index:  1\n",
      "input index:  [ 0.30787858  0.95142566]\n",
      "target index:  0\n",
      "input index:  [ 0.74305834 -0.66922665]\n",
      "target index:  1\n",
      "input index:  [-0.99953495  0.03049414]\n",
      "target index:  0\n",
      "input index:  [ 0.98923656  0.14632509]\n",
      "target index:  1\n",
      "input index:  [-0.17434003  0.98468551]\n",
      "target index:  1\n",
      "input index:  [ 0.35412082  0.93519968]\n",
      "target index:  0\n",
      "input index:  [ 0.99014727 -0.14002997]\n",
      "target index:  1\n",
      "input index:  [ 0.9160975  -0.40095557]\n",
      "target index:  1\n",
      "input index:  [ 0.99463996 -0.10339898]\n",
      "target index:  1\n",
      "input index:  [ 0.91372597 -0.40633097]\n",
      "target index:  1\n",
      "input index:  [ 0.91769328 -0.39728963]\n",
      "target index:  1\n",
      "input index:  [ 0.44138089 -0.89731985]\n",
      "target index:  1\n",
      "input index:  [ 0.98654437  0.16349374]\n",
      "target index:  1\n",
      "input index:  [ 0.79635695  0.60482692]\n",
      "target index:  0\n",
      "input index:  [ 0.28864432  0.9574364 ]\n",
      "target index:  0\n",
      "input index:  [-0.03451603  0.99940414]\n",
      "target index:  1\n",
      "input index:  [ 0.94871775 -0.31612438]\n",
      "target index:  1\n",
      "input index:  [ 0.93533059 -0.35377492]\n",
      "target index:  1\n",
      "input index:  [ 0.97438538  0.22488471]\n",
      "target index:  0\n",
      "input index:  [ 0.84266084  0.53844471]\n",
      "target index:  0\n",
      "input index:  [ 0.71686981  0.69720706]\n",
      "target index:  0\n",
      "input index:  [ 0.9714869  -0.23709322]\n",
      "target index:  1\n",
      "input index:  [-0.99445674 -0.10514652]\n",
      "target index:  0\n",
      "input index:  [-0.47450734  0.88025155]\n",
      "target index:  0\n",
      "input index:  [ 0.98953195  0.14431397]\n",
      "target index:  1\n",
      "input index:  [-0.90891162  0.41698882]\n",
      "target index:  0\n",
      "input index:  [ 0.76895175 -0.63930681]\n",
      "target index:  1\n",
      "input index:  [ 0.19469947  0.98086295]\n",
      "target index:  0\n",
      "input index:  [-0.98347667  0.18103491]\n",
      "target index:  0\n",
      "input index:  [ 0.8177076 -0.5756338]\n",
      "target index:  1\n",
      "input index:  [ 0.06290378  0.9980196 ]\n",
      "target index:  0\n",
      "input index:  [ 0.9826299   0.18557609]\n",
      "target index:  0\n",
      "input index:  [ 0.98639962  0.16436479]\n",
      "target index:  1\n",
      "input index:  [-0.72962975  0.6838424 ]\n",
      "target index:  0\n",
      "input index:  [ 0.59921092  0.8005912 ]\n",
      "target index:  0\n",
      "input index:  [ 0.93598791 -0.35203214]\n",
      "target index:  1\n",
      "input index:  [ 0.98880558 -0.1492097 ]\n",
      "target index:  1\n",
      "input index:  [ 0.96858873  0.24866818]\n",
      "target index:  0\n",
      "input index:  [ 0.9075739   0.41989238]\n",
      "target index:  0\n",
      "input index:  [-0.36402594  0.93138881]\n",
      "target index:  0\n",
      "input index:  [ 0.42903     0.90329024]\n",
      "target index:  0\n",
      "input index:  [ 0.99580886  0.0914588 ]\n",
      "target index:  0\n",
      "input index:  [-0.77397149  0.63322045]\n",
      "target index:  0\n",
      "input index:  [ 0.02315858  0.9997318 ]\n",
      "target index:  0\n",
      "input index:  [ 0.07664526  0.99705843]\n",
      "target index:  0\n",
      "input index:  [ 0.95824707  0.28594153]\n",
      "target index:  0\n",
      "input index:  [ 0.9294835  0.3688637]\n",
      "target index:  0\n",
      "input index:  [-0.16677883  0.98599433]\n",
      "target index:  0\n",
      "input index:  [ 0.99999944 -0.00105388]\n",
      "target index:  1\n",
      "input index:  [ 0.46015799  0.88783705]\n",
      "target index:  0\n",
      "input index:  [ 0.05859329  0.99828194]\n",
      "target index:  0\n",
      "input index:  [-0.21340553 -0.97696371]\n",
      "target index:  1\n",
      "input index:  [ 0.47757102  0.87859315]\n",
      "target index:  0\n",
      "input index:  [-0.20521705  0.97871649]\n",
      "target index:  0\n",
      "input index:  [ 0.99452772 -0.10447307]\n",
      "target index:  1\n",
      "input index:  [-0.49609224  0.86826983]\n",
      "target index:  0\n",
      "input index:  [-0.53726878  0.84341108]\n",
      "target index:  0\n",
      "input index:  [ 0.95596079 -0.2934944 ]\n",
      "target index:  1\n",
      "input index:  [-0.33066687  0.94374754]\n",
      "target index:  0\n",
      "input index:  [ 0.99900185  0.04466877]\n",
      "target index:  1\n",
      "input index:  [  9.99999613e-01   8.80270368e-04]\n",
      "target index:  1\n",
      "input index:  [ 0.98477704 -0.17382228]\n",
      "target index:  1\n",
      "input index:  [ 0.97109117  0.2387089 ]\n",
      "target index:  1\n",
      "input index:  [ 0.89459026 -0.4468873 ]\n",
      "target index:  1\n",
      "input index:  [ 0.97589661  0.21823336]\n",
      "target index:  1\n",
      "input index:  [ 0.97651182  0.21546383]\n",
      "target index:  1\n",
      "input index:  [ 0.99553967  0.09434385]\n",
      "target index:  0\n",
      "input index:  [-0.99948036 -0.03223381]\n",
      "target index:  0\n",
      "input index:  [ 0.99936025  0.03576434]\n",
      "target index:  1\n",
      "input index:  [ 0.99493695  0.10050108]\n",
      "target index:  1\n",
      "input index:  [-0.44670859  0.89467952]\n",
      "target index:  1\n",
      "input index:  [ 0.94737417 -0.3201284 ]\n",
      "target index:  1\n",
      "input index:  [ 0.70736473  0.70684874]\n",
      "target index:  1\n",
      "input index:  [-0.92368007  0.38316462]\n",
      "target index:  0\n",
      "input index:  [ 0.49150491  0.87087481]\n",
      "target index:  0\n",
      "input index:  [-0.65792672  0.75308195]\n",
      "target index:  0\n",
      "input index:  [ 0.33102167  0.94362315]\n",
      "target index:  0\n",
      "input index:  [ 0.81321115  0.58196876]\n",
      "target index:  0\n",
      "input index:  [ 0.89343425 -0.44919398]\n",
      "target index:  1\n",
      "input index:  [-0.99655695  0.08291103]\n",
      "target index:  0\n",
      "input index:  [ 0.66275502 -0.74883629]\n",
      "target index:  1\n",
      "input index:  [ 0.98586709 -0.16752934]\n",
      "target index:  1\n",
      "input index:  [ 0.83481324  0.55053325]\n",
      "target index:  0\n",
      "input index:  [ 0.90763117 -0.41976858]\n",
      "target index:  1\n",
      "input index:  [ 0.76761876 -0.64090673]\n",
      "target index:  1\n",
      "input index:  [-0.74384634  0.66835067]\n",
      "target index:  0\n",
      "input index:  [-0.9911609   0.13266525]\n",
      "target index:  0\n",
      "input index:  [ 0.92238668 -0.38626781]\n",
      "target index:  1\n",
      "input index:  [-0.99486586  0.10120234]\n",
      "target index:  0\n",
      "input index:  [-0.00958166  0.99995409]\n",
      "target index:  0\n",
      "input index:  [ 0.41897574  0.90799743]\n",
      "target index:  0\n",
      "input index:  [ 0.99947654 -0.03235187]\n",
      "target index:  0\n",
      "input index:  [ 0.75282476  0.65822099]\n",
      "target index:  0\n",
      "input index:  [ 0.75767119 -0.65263648]\n",
      "target index:  1\n",
      "input index:  [ 0.92503294 -0.37988689]\n",
      "target index:  1\n",
      "input index:  [ 0.95242449  0.30477464]\n",
      "target index:  0\n",
      "input index:  [ 0.99937503  0.03534898]\n",
      "target index:  1\n",
      "input index:  [ 0.08259033  0.99658358]\n",
      "target index:  1\n",
      "input index:  [ 0.88709583 -0.4615853 ]\n",
      "target index:  1\n",
      "input index:  [ 0.7285953  -0.68494444]\n",
      "target index:  1\n",
      "input index:  [ 0.7933292  -0.60879289]\n",
      "target index:  1\n",
      "input index:  [ 0.98763531  0.15676894]\n",
      "target index:  1\n",
      "input index:  [-0.30455074  0.95249612]\n",
      "target index:  0\n",
      "input index:  [ 0.16912402  0.98559478]\n",
      "target index:  1\n",
      "input index:  [ 0.82584758 -0.56389341]\n",
      "target index:  1\n",
      "input index:  [ 0.98843426 -0.15164997]\n",
      "target index:  1\n",
      "input index:  [ 0.7865661  -0.61750609]\n",
      "target index:  1\n",
      "input index:  [ 0.90835206 -0.41820634]\n",
      "target index:  1\n",
      "input index:  [ 0.44130994  0.89735475]\n",
      "target index:  0\n",
      "input index:  [ 0.92147936  0.38842734]\n",
      "target index:  0\n",
      "input index:  [ 0.56607385 -0.82435454]\n",
      "target index:  1\n"
     ]
    }
   ],
   "source": [
    "## TEST MODEL\n",
    "inputs = preprocessing.normalize(test_X)\n",
    "target = test_y\n",
    "target = np.array(target)\n",
    "print(len(inputs))\n",
    "print(len(target))\n",
    "#tol=1e-7\n",
    "#maxrounds=1000\n",
    "#iter=0\n",
    "error = 99.0\n",
    "#while abs(error) > tol:\n",
    "error_res = []\n",
    "result = []\n",
    "#result = np.array(result)\n",
    "\n",
    "for i in range(len(inputs)):\n",
    "    print (\"input index: \", inputs[i])\n",
    "    print (\"target index: \", target[i])\n",
    "        \n",
    "    ### START OF FORWARD PROPAGATION FUNCTION CALLS\n",
    "    # test get_sigmoid_output \n",
    "    hidden_layer = get_sigmoid_output(Weights1, inputs[i], bias_1)\n",
    "    ##print (\"hidden_layer result:\", hidden_layer)\n",
    "        \n",
    "    # test get_output\n",
    "    output = get_output(hidden_layer, Weights2, bias_2)\n",
    "    #  print (\"output:\", output)\n",
    "    result.append(output)\n",
    "        \n",
    "    # call error function\n",
    "    error = get_error(target[t], output)\n",
    "    error_res.append(error)\n",
    "    #print(\"error:\", error)\n",
    "        \n",
    "    # END OF FORWARD PROPAGATION FUNCTION CALLS\n",
    "result = np.array(result)  \n",
    "error_res = np.array(error_res)\n",
    "target = np.array(target)\n",
    "#print(\"Target:\", target)        \n",
    "#print(\"Results: \", result)\n",
    "#print(\"Error:\", error_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "120\n",
      "1e-07\n",
      "True Negative:  0  -  0.992047775115\n",
      "False Positive:  1  -  0.93164272077\n",
      "False Positive:  1  -  0.991651061246\n",
      "True Negative:  0  -  0.957736382608\n",
      "False Positive:  1  -  0.984571710239\n",
      "False Positive:  1  -  0.986756885654\n",
      "False Positive:  1  -  0.975525144444\n",
      "False Positive:  1  -  0.987422497351\n",
      "False Positive:  1  -  0.988694996968\n",
      "True Negative:  0  -  0.991653866697\n",
      "False Positive:  1  -  0.972762722113\n",
      "True Negative:  0  -  0.944691746217\n",
      "False Positive:  1  -  0.989709513958\n",
      "False Positive:  1  -  0.989154939906\n",
      "True Negative:  0  -  0.991767378854\n",
      "False Positive:  1  -  0.986854125291\n",
      "False Positive:  1  -  0.982157280545\n",
      "False Positive:  1  -  0.98732089342\n",
      "False Positive:  1  -  0.982027058799\n",
      "False Positive:  1  -  0.982245107609\n",
      "False Positive:  1  -  0.954931200522\n",
      "False Positive:  1  -  0.989833289586\n",
      "True Negative:  0  -  0.991833550439\n",
      "True Negative:  0  -  0.991601429213\n",
      "False Positive:  1  -  0.990185945102\n",
      "False Positive:  1  -  0.984003141399\n",
      "False Positive:  1  -  0.983229932676\n",
      "True Negative:  0  -  0.990242173109\n",
      "True Negative:  0  -  0.991657908925\n",
      "True Negative:  0  -  0.992004702825\n",
      "False Positive:  1  -  0.985422187392\n",
      "True Negative:  0  -  0.936738440297\n",
      "True Negative:  0  -  0.98532863331\n",
      "False Positive:  1  -  0.989694731356\n",
      "True Negative:  0  -  0.966117152103\n",
      "False Positive:  1  -  0.974196050003\n",
      "True Negative:  0  -  0.991299285044\n",
      "True Negative:  0  -  0.953414088289\n",
      "False Positive:  1  -  0.976853464382\n",
      "True Negative:  0  -  0.990732718782\n",
      "True Negative:  0  -  0.989986283022\n",
      "False Positive:  1  -  0.989839455251\n",
      "True Negative:  0  -  0.978153342622\n",
      "True Negative:  0  -  0.992071738806\n",
      "False Positive:  1  -  0.983267266481\n",
      "False Positive:  1  -  0.986731303724\n",
      "True Negative:  0  -  0.990387280443\n",
      "True Negative:  0  -  0.991240709557\n",
      "True Negative:  0  -  0.987084344062\n",
      "True Negative:  0  -  0.991914277182\n",
      "True Negative:  0  -  0.989283844756\n",
      "True Negative:  0  -  0.976085694566\n",
      "True Negative:  0  -  0.99052426023\n",
      "True Negative:  0  -  0.990800446474\n",
      "True Negative:  0  -  0.990600777464\n",
      "True Negative:  0  -  0.991019164363\n",
      "True Negative:  0  -  0.989219569651\n",
      "False Positive:  1  -  0.988449485565\n",
      "True Negative:  0  -  0.99196187048\n",
      "True Negative:  0  -  0.990711024191\n",
      "False Positive:  1  -  0.918307456832\n",
      "True Negative:  0  -  0.991984991628\n",
      "True Negative:  0  -  0.988878853214\n",
      "False Positive:  1  -  0.987307718566\n",
      "True Negative:  0  -  0.98491896286\n",
      "True Negative:  0  -  0.984062878496\n",
      "False Positive:  1  -  0.984436095787\n",
      "True Negative:  0  -  0.987521847209\n",
      "False Positive:  1  -  0.988881502878\n",
      "False Positive:  1  -  0.988468591975\n",
      "False Positive:  1  -  0.98638971645\n",
      "False Positive:  1  -  0.990327381129\n",
      "False Positive:  1  -  0.980986394106\n",
      "False Positive:  1  -  0.990200306326\n",
      "False Positive:  1  -  0.990182704602\n",
      "True Negative:  0  -  0.989307425009\n",
      "True Negative:  0  -  0.941007094541\n",
      "False Positive:  1  -  0.988800502981\n",
      "False Positive:  1  -  0.989357291041\n",
      "False Positive:  1  -  0.985820947624\n",
      "False Positive:  1  -  0.983924132996\n",
      "False Positive:  1  -  0.992017145369\n",
      "True Negative:  0  -  0.964399343949\n",
      "True Negative:  0  -  0.992001653476\n",
      "True Negative:  0  -  0.980822584192\n",
      "True Negative:  0  -  0.991712875839\n",
      "True Negative:  0  -  0.991777818147\n",
      "False Positive:  1  -  0.980923956601\n",
      "True Negative:  0  -  0.947758256873\n",
      "False Positive:  1  -  0.968208703382\n",
      "False Positive:  1  -  0.986478796116\n",
      "True Negative:  0  -  0.991693007406\n",
      "False Positive:  1  -  0.981693857262\n",
      "False Positive:  1  -  0.974122662054\n",
      "True Negative:  0  -  0.977531268375\n",
      "True Negative:  0  -  0.950643877725\n",
      "False Positive:  1  -  0.982504464522\n",
      "True Negative:  0  -  0.948822632263\n",
      "True Negative:  0  -  0.990337680031\n",
      "True Negative:  0  -  0.991897208133\n",
      "True Negative:  0  -  0.988129486981\n",
      "True Negative:  0  -  0.991943511466\n",
      "False Positive:  1  -  0.973573646455\n",
      "False Positive:  1  -  0.982651460663\n",
      "True Negative:  0  -  0.990702463168\n",
      "False Positive:  1  -  0.988796688621\n",
      "False Positive:  1  -  0.990829082124\n",
      "False Positive:  1  -  0.980582200101\n",
      "False Positive:  1  -  0.971954790358\n",
      "False Positive:  1  -  0.975530933509\n",
      "False Positive:  1  -  0.98978532013\n",
      "True Negative:  0  -  0.9878396022\n",
      "False Positive:  1  -  0.991203109787\n",
      "False Positive:  1  -  0.977292734258\n",
      "False Positive:  1  -  0.98669824307\n",
      "False Positive:  1  -  0.975161924375\n",
      "False Positive:  1  -  0.981733167891\n",
      "True Negative:  0  -  0.991934004382\n",
      "True Negative:  0  -  0.991107206791\n",
      "False Positive:  1  -  0.962517931487\n",
      "True Positive:  0\n",
      "True Negative:  57\n",
      "False Positive:  63\n",
      "False Negative:  0\n"
     ]
    }
   ],
   "source": [
    "# calculate the accuracy of the NN\n",
    "print(len(target))\n",
    "print(len(result))\n",
    "print(tol)\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "for i in range(len(target)):\n",
    "        \n",
    "        if (target[i] == 1 and target[i]-result[i] <= tol):\n",
    "            TP = TP + 1\n",
    "            print(\"True Positive: \", target[i], \" - \", result[i])\n",
    "\n",
    "        if (target[i] == 0 and target[i]-result[i] <= tol):\n",
    "            TN = TN + 1\n",
    "            print(\"True Negative: \",target[i], \" - \", result[i])\n",
    "            \n",
    "        if (target[i] == 1 and target[i]-result[i] > tol):\n",
    "            FP = FP + 1\n",
    "            print(\"False Positive: \",target[i], \" - \", result[i])\n",
    "            \n",
    "        if (target[i] == 0 and target[i]-result[i] > tol):\n",
    "            FN = FN + 1\n",
    "            print(\"False Negative: \",target[i], \" - \", result[i])\n",
    "        \n",
    "print(\"True Positive: \", TP)\n",
    "print(\"True Negative: \", TN)\n",
    "print(\"False Positive: \", FP)\n",
    "print(\"False Negative: \", FN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
