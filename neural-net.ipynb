{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mnist import MNIST\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X): 400\n",
      "len(X[0]): 3\n",
      "len(X[:,0]): 400\n",
      "X: nsamples = 400 , nattribs = 3\n",
      "(280, 3) (280,)\n",
      "(120, 3) (120,)\n",
      "length train X 280\n",
      "length test X 120\n",
      "length train y 280\n",
      "length test y 120\n",
      "train:  (280, 2) (280,)\n",
      "test:  (120, 2) (120,)\n"
     ]
    }
   ],
   "source": [
    "# set up training rate alpha\n",
    "alpha = 0.5\n",
    "\n",
    "# Use pandas to read the CSV file as a dataframe\n",
    "df = pd.read_csv(\"moons400.csv\")\n",
    "# The y values are those labelled 'Class': extract their values\n",
    "y = df['Class'].values\n",
    "\n",
    "# The x values are all other columns\n",
    "#del df['Class']    # drop the 'Class' column from the dataframe\n",
    "X = df.as_matrix() # convert the remaining columns to a numpy array\n",
    "# Some examples of working with the data, to look at rows/columns\n",
    "print (\"len(X):\", len(X))            # outer array: one per sample\n",
    "print (\"len(X[0]):\", len(X[0]))      # each inner array is the attributes of one sample\n",
    "print (\"len(X[:,0]):\", len(X[:,0]))  # select column 0 from array\n",
    "\n",
    "# np.shape returns all dimensions of the array\n",
    "(nsamples, nattribs) = np.shape(X)\n",
    "print (\"X: nsamples =\", nsamples, \", nattribs =\", nattribs)\n",
    "\n",
    "# using sklearn.model_selection.train_test_split to split up data into train and test sets split 70/30\n",
    "train_X, test_X, train_y, test_y = train_test_split(df, y, test_size=0.30)\n",
    "\n",
    "print(train_X.shape, train_y.shape)\n",
    "print(test_X.shape, test_y.shape)\n",
    "\n",
    "print(\"length train X\", len(train_X))\n",
    "print(\"length test X\", len(test_X))\n",
    "print(\"length train y\", len(train_y))\n",
    "print(\"length test y\", len(test_y))\n",
    "\n",
    "# The x train and test values are all other columns\n",
    "#print(train_X)\n",
    "del train_X['Class']    # drop the 'Class' column from the Train and test dataframe\n",
    "del test_X['Class']\n",
    "#print(test_X)\n",
    "\n",
    "print(\"train: \", train_X.shape, train_y.shape)\n",
    "print(\"test: \", test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasubset: dsamples = 280 , dattribs = 2\n"
     ]
    }
   ],
   "source": [
    "#datasubset_x = X[0:2]\n",
    "datasubset_x = train_X[0:2]\n",
    "datasubset_x = train_X\n",
    "(dsamples, dattribs) = np.shape(datasubset_x)\n",
    "print(\"datasubset: dsamples =\", dsamples, \", dattribs =\", dattribs)\n",
    "\n",
    "# print(datasubset_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rescale the inputs using normalization \n",
    "inputs = preprocessing.normalize(datasubset_x)\n",
    "# inputs = datasubset_x\n",
    "# inputs[0,0] = 0.05\n",
    "# inputs[0,1] = 0.1\n",
    "# print(inputs)\n",
    "inputs = np.array(inputs, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# target = y[0:20]\n",
    "target = train_y[0:2]\n",
    "target = train_y\n",
    "# target = 0.01\n",
    "#print(target)\n",
    "target = np.array(target, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up training rate alpha\n",
    "alpha = 0.1\n",
    "\n",
    "# initialise the weights for the network based on the input layers, the number of hidden layers, the number of output layers\n",
    "def initialise_input_weights(n_inputs, n_hidden_inputs):\n",
    " hidden_layer_weights = list()\n",
    " for i in range(n_hidden_inputs):\n",
    "  #for j in range(n_inputs):\n",
    "   weight = np.random.randn(n_inputs)*np.sqrt(1/(n_inputs)**(n_hidden_inputs-1)) \n",
    "    #reference for above https://www.coursera.org/learn/deep-neural-network/lecture/RwqYe/weight-initialization-for-deep-networks\n",
    "   hidden_layer_weights.append(weight)\n",
    " \n",
    " input_weights = np.array([hidden_layer_weights])\n",
    " input_weights = np.reshape(input_weights, (n_inputs, n_hidden_inputs))\n",
    " return input_weights; \n",
    "\n",
    "def initialise_output_weights(n_hidden_inputs,n_outputs):\n",
    " output_layer_weights = list()\n",
    " for i in range(n_outputs):\n",
    "  for j in range(n_hidden_inputs):\n",
    "   weight = np.random.random(1)[0]\n",
    "   output_layer_weights.append(weight) \n",
    "  \n",
    " if n_outputs == 1:\n",
    "  output_weights = np.array([output_layer_weights])\n",
    " elif n_outputs > 1:\n",
    "  output_weights = np.array([output_layer_weights])  \n",
    "  output_weights = np.reshape(output_weights, (n_hidden_inputs,n_outputs))\n",
    " \n",
    " return output_weights;\n",
    "    \n",
    "#initialise the bias for the network based on the number of hidden layers and the output layer bias\n",
    "def initialise_bias(n_hidden_layer):\n",
    " hidden_layer_bias = list()    \n",
    " for i in range(n_hidden_layer):\n",
    "  bias = np.random.random(1)[0]\n",
    "  hidden_layer_bias.append(bias)\n",
    " \n",
    " output_layer_bias = [np.random.random(1)[0]]\n",
    " network_bias = [[hidden_layer_bias],[output_layer_bias]]\n",
    " return network_bias;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FORWARD PROPAGATION USING FUNCTIONS\n",
    "# do the above using a function\n",
    "# convert calculations to function for hidden layer\n",
    "def get_sigmoid_output(weights, input, bias):\n",
    "    hidden_layer = input * weights \n",
    "    hidden_layer = np.sum(hidden_layer, axis=1) + bias\n",
    "    hidden_layer = 1/(1+np.exp(-hidden_layer))\n",
    "    return hidden_layer;\n",
    "\n",
    "def get_output(sigmoid_out, weights, bias):\n",
    "    output = (sigmoid_out*weights)\n",
    "    output = 1/(1+np.exp(-(np.sum(output)+bias)))\n",
    "    return output;\n",
    "\n",
    "# get the error \n",
    "# error_o = (0.5*(target - output)**2)\n",
    "# print(error_o)\n",
    "\n",
    "#convert to a function\n",
    "# I think this needs to change to accept a numpy array as well\n",
    "# we should end up with a data frame we can plot against the number of executions\n",
    "def get_error(t, o):\n",
    "    error_o = (0.5*(t - o)**2)\n",
    "    return error_o;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FUNCTIONS FOR BACK PROPAGATION OF OUTPUT\n",
    "# calculate derivative of error at output layer\n",
    "\n",
    "# deriv_wrt_out = -(target - output)\n",
    "# change above to function\n",
    "def deltaErr_wrt_out(targ, outp):\n",
    "    result = -(targ - outp)\n",
    "    return result;  \n",
    "\n",
    "# calculate the derivation of the error output wrt the net\n",
    "# derivout_wrt_net = output*(1-output)\n",
    "# change above to function\n",
    "def deltaOut_wrt_net(outp):\n",
    "    result = outp*(1-outp)\n",
    "    return result;   \n",
    "\n",
    "# change above to function\n",
    "# calculate derivative of error wrt to output layer weight OLW_Deriv\n",
    "def deltaErr_ow(deriv_wrt_out, derivout_wrt_net, activation):\n",
    "    OLW_Deriv = deriv_wrt_out*derivout_wrt_net*activation\n",
    "   # print(OLW_Deriv)\n",
    "    return OLW_Deriv;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# FUNCTIONS FOR BACK PROPAGATION OF HIDDEN LAYER\n",
    "# calculate derivative of error at hidden layer\n",
    "\n",
    "# deriv_out_wrt_hL =  Weights2 * deriv_wrt_out *derivout_wrt_net\n",
    "# print (deriv_out_wrt_hL)\n",
    "# convert above to function\n",
    "def deltaOut_hL(deriv_wrt_out, derivout_wrt_net, weights):\n",
    "    deriv_out_wrt_hL = deriv_wrt_out *derivout_wrt_net *  weights\n",
    "    return deriv_out_wrt_hL;\n",
    "\n",
    "# deriv_out_wrt_nethL = activation*(1-activation)\n",
    "# convert above to function\n",
    "def deltaOut_netHL(activation):\n",
    "    activation = activation*(1-activation)\n",
    "    return activation;\n",
    "\n",
    "# deriv_wrt_wi = deriv_out_wrt_hL*deriv_out_wrt_nethL*Weights1\n",
    "# convert above to function\n",
    "def deltaErr_wi(deriv_out_wrt_hL, deriv_out_wrt_nethL, weights):\n",
    "    deriv_wrt_wi = deriv_out_wrt_hL*deriv_out_wrt_nethL*weights\n",
    "    return deriv_wrt_wi;\n",
    "\n",
    "# convert the above to a function\n",
    "def calc_adjusted_weights(W, deriv):\n",
    "    W = W - (alpha*deriv)\n",
    "    return W;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: samples = 280 , attribs = 2\n",
      "Length of inputs 280\n",
      "input Weights 2\n",
      "[[ 0.28866915 -0.60956944]\n",
      " [ 0.12669093  0.17858478]]\n",
      "output Weights 1\n",
      "Network Bias 2\n"
     ]
    }
   ],
   "source": [
    "# set up weights and biases \n",
    "(train_samples, train_shape) = np.shape(inputs)\n",
    "print (\"train: samples =\", train_samples, \", attribs =\", train_shape)\n",
    "\n",
    "# Test weights and bias initialisation based on network inputs, hidden layers, and outputs\n",
    "# first line of moons.csv\n",
    "#input_X =[[2.07106946, 0.41152931]]\n",
    "\n",
    "#(nsamples, nattribs) = np.shape(input_X)\n",
    "n_inputs = train_shape\n",
    "\n",
    "n_hidden_layer = 1\n",
    "n_hidden_inputs = 2\n",
    "n_outputs = 1\n",
    "\n",
    "# normalise training data\n",
    "# rescale the inputs using normalization \n",
    "# mnist_train = preprocessing.normalize(filtered_images)\n",
    "#print(\"normalised inputs\",inputs)\n",
    "\n",
    "Weights1 = np.array(initialise_input_weights(n_inputs, n_hidden_inputs), dtype=np.float64)\n",
    "Weights2 = np.array(initialise_output_weights(n_hidden_inputs, n_outputs), dtype=np.float64)\n",
    "#network_weights = initialise_weights(n_inputs, n_hidden_inputs, n_outputs)\n",
    "bias = np.array(initialise_bias(n_hidden_layer), dtype=np.float64)\n",
    "\n",
    "print(\"Length of inputs\",len(inputs))\n",
    "#print(\"actual y\",input_y)\n",
    "print(\"input Weights\", len(Weights1))\n",
    "print(Weights1)\n",
    "print(\"output Weights\", len(Weights2))\n",
    "print(\"Network Bias\", len(bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of inputs 120\n",
      "input Weights 2\n",
      "output Weights 1\n",
      "Network Bias 2\n",
      "[[ 10.36698256  -1.7652734 ]\n",
      " [  4.54985476   0.51716989]]\n",
      "[[ 7.20885252 -1.63263479]]\n",
      "[[[-9.99336772]]\n",
      "\n",
      " [[-1.68657535]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of inputs\",len(inputs))\n",
    "#print(\"actual y\",input_y)\n",
    "print(\"input Weights\", len(Weights1))\n",
    "print(\"output Weights\", len(Weights2))\n",
    "print(\"Network Bias\", len(bias))\n",
    "\n",
    "print(Weights1)\n",
    "print (Weights2)\n",
    "print(bias)\n",
    "#print(deltaErrOut_hL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-20 20:56:01.941430\n",
      "\n",
      "Finished after  3001  error = [[ 0.01223564]] target= 0.0 , output= [[ 0.15643296]] input final= [-0.99838555  0.05680041]\n",
      "2018-02-20 20:56:41.344958\n",
      "Weights1 adjusted: [[ 10.36698256  -1.7652734 ]\n",
      " [  4.54985476   0.51716989]]\n",
      "Weights2 adjusted: [[ 7.20885252 -1.63263479]]\n"
     ]
    }
   ],
   "source": [
    "# use a loop to iterate through the dataset\n",
    "# and present records 1 by 1\n",
    "# for i in np.nditer(inputs, flags=['external_loop'], order='C'):\n",
    "#for i in range(len(inputs)):\n",
    "#    print (i)\n",
    "#    for t in range((target[i])):## this part is not working because it loops through the whole target array each time\n",
    "#        print(t)  ## not what we want\n",
    "alpha = 0.01\n",
    "#TRAIN MODEL\n",
    "print(datetime.datetime.now())\n",
    "threshold=1e-5\n",
    "maxrounds=3000\n",
    "iter=0\n",
    "error = 99.0\n",
    "while abs(error) > threshold:\n",
    "    for i in range(len(inputs)):\n",
    "        \n",
    "        # START OF FORWARD PROPAGATION FUNCTION CALLS\n",
    "        # test get_sigmoid_output \n",
    "        hidden_layer = get_sigmoid_output(Weights1, inputs[i], bias[0])\n",
    "        #print (\"hidden_layer result:\", hidden_layer)\n",
    "\n",
    "        # test get_output\n",
    "        output = get_output(hidden_layer, Weights2, bias[1])\n",
    "        #print (\"output:\", output)\n",
    "\n",
    "        # call error function\n",
    "        error = get_error(target[i], output)\n",
    "       # print(\"error:\", error)\n",
    "\n",
    "        # END OF FORWARD PROPAGATION FUNCTION CALLS\n",
    "\n",
    "        # START OF BACK PROPAGATION FOR OUTPUT LAYER\n",
    "        #test function deltaErr_wrt_out\n",
    "        deltaErr_out = deltaErr_wrt_out(target[i], output)\n",
    "        # print(deltaErr_out)\n",
    "\n",
    "        #test function\n",
    "        deltaOut_net = deltaOut_wrt_net(output)\n",
    "        # print(deltaOut_net)\n",
    "\n",
    "        deltaErrtot_ow = deltaErr_ow(deltaErr_out, deltaOut_net, hidden_layer)\n",
    "        # print(deltaErrtot_ow)\n",
    "\n",
    "        # END OF BACK PROPAGATION FOR OUTPUT LAYER\n",
    "\n",
    "        # START BACK PROPAGATION OF HIDDEN LAYER\n",
    "        # calculate derivative of error at hidden layer\n",
    "\n",
    "        # test function deltaOut_hL\n",
    "        deltaErrOut_hL = deltaOut_hL(deltaErr_out, deltaOut_net, Weights2)\n",
    "        # print(deltaErrOut_hL)\n",
    "\n",
    "        #test function \n",
    "        deltaErrOut_netHL = deltaOut_netHL(hidden_layer)\n",
    "        # print(deltaErrOut_netHL)\n",
    "\n",
    "        deltaErrH_wi = deltaErr_wi(deltaErrOut_hL, deltaErrOut_netHL, Weights1)\n",
    "        # print(deltaErrH_wi)\n",
    "\n",
    "        # same calculation as above but with Weights matrix \n",
    "        # calculate adjusted weights using function\n",
    "        Weights2 = calc_adjusted_weights(Weights2, deltaErrtot_ow)\n",
    "        Weights1 = calc_adjusted_weights(Weights1, deltaErrH_wi)\n",
    "        bias[1] = calc_adjusted_weights(bias[1], deltaErr_out)\n",
    "        bias[0] = calc_adjusted_weights(bias[0], 0.5*np.sum(deltaErrOut_hL, dtype=np.float64))\n",
    "\n",
    "        # END OF BACK PROPAGATION OF HIDDEN LAYER\n",
    "\n",
    "    iter=iter+1\n",
    "    \n",
    "    if (iter > maxrounds):\n",
    "        break\n",
    "\n",
    "print (\"\\nFinished after \", iter, \" error =\", error, \"target=\", target[i], \", output=\", output, \"input final=\", inputs[i])    \n",
    "print(datetime.datetime.now())\n",
    "print (\"Weights1 adjusted:\", Weights1)\n",
    "print (\"Weights2 adjusted:\", Weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference https://pypi.python.org/pypi/python-mnist\n",
    "# https://github.com/sorki/python-mnist/blob/master/mnist/loader.py\n",
    "# TRAIN MNIST DATA\n",
    "\n",
    "mndata = MNIST('./mnist')\n",
    "images, labels = mndata.load_training()\n",
    "\n",
    "processed_images = mndata.process_images_to_numpy(images)\n",
    "# print(processed_images[0:2])\n",
    "\n",
    "target = np.array(labels)\n",
    "# print(target[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 6, 6, 0, 6, 0, 6, 0, 6, 0]\n",
      "[0, 1, 1, 0, 1, 0, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# set up 2 lists to filter the MNIST data into\n",
    "# keeping only 0 and 6 to classify\n",
    "# TRAIN MNIST DATA\n",
    "\n",
    "filtered_labels = []\n",
    "filtered_images = []\n",
    "for i in range(len(target)):\n",
    "    if target[i]==0 or target[i]==6:\n",
    "        filtered_labels.append(target[i])\n",
    "        filtered_images.append(processed_images[i])\n",
    "        \n",
    "# remap the value 6 to 1, so classification is binary\n",
    "\n",
    "#print(filtered_labels[0:10])\n",
    "\n",
    "for i in range(len(filtered_labels)):\n",
    "    if filtered_labels[i]==6:\n",
    "        filtered_labels[i]=1\n",
    "\n",
    "#print(filtered_labels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert the lists to arrays\n",
    "# TRAIN MNIST DATA\n",
    "filtered_labels = np.array(filtered_labels)\n",
    "\n",
    "filtered_images = np.array(filtered_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# MNIST TEST DATA\n",
    "test_images, test_labels = mndata.load_testing()\n",
    "\n",
    "test_images = mndata.process_images_to_numpy(test_images)\n",
    "#print(processed_images[0:2])\n",
    "\n",
    "test_target = np.array(test_labels)\n",
    "\n",
    "# set up 2 lists to filter the MNIST data into\n",
    "# keeping only 0 and 6 to classify\n",
    "# TEST MNIST DATA\n",
    "\n",
    "filtered_test_labels = []\n",
    "filtered_test_images = []\n",
    "for i in range(len(target)):\n",
    "    if target[i]==0 or target[i]==6:\n",
    "        filtered_test_labels.append(target[i])\n",
    "        filtered_test_images.append(processed_images[i])\n",
    "        \n",
    "# remap the value 6 to 1, so classification is binary\n",
    "\n",
    "#print(filtered_labels[0:10])\n",
    "\n",
    "for i in range(len(filtered_test_labels)):\n",
    "    if filtered_test_labels[i]==6:\n",
    "        filtered_test_labels[i]=1\n",
    "        \n",
    "# convert the lists to arrays\n",
    "# TEST MNIST DATA\n",
    "filtered_test_labels = np.array(filtered_test_labels)\n",
    "\n",
    "filtered_test_images = np.array(filtered_test_images)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 1, 0, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(filtered_test_labels[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: samples = 11841 , attribs = 784\n",
      "Length of inputs 11841\n",
      "input Weights 784\n",
      "output Weights 1\n",
      "Network Bias 2\n"
     ]
    }
   ],
   "source": [
    "# set up weights and biases for MNIST data, get nattribs value\n",
    "# TRAIN MNIST DATA\n",
    "\n",
    "(train_samples, train_shape) = np.shape(filtered_images)\n",
    "print (\"train: samples =\", train_samples, \", attribs =\", train_shape)\n",
    "\n",
    "# Test weights and bias initialisation based on network inputs, hidden layers, and outputs\n",
    "# first line of moons.csv\n",
    "#input_X =[[2.07106946, 0.41152931]]\n",
    "\n",
    "#(nsamples, nattribs) = np.shape(input_X)\n",
    "n_inputs = train_shape\n",
    "n_hidden_layer = 1\n",
    "n_hidden_inputs = 2\n",
    "n_outputs = 1\n",
    "\n",
    "# normalise training data\n",
    "# rescale the inputs using normalization \n",
    "mnist_train = preprocessing.normalize(filtered_images)\n",
    "#print(\"normalised inputs\",inputs)\n",
    "\n",
    "input_weights = np.array(initialise_input_weights(n_inputs, n_hidden_inputs))\n",
    "output_weights = np.array(initialise_output_weights(n_hidden_inputs, n_outputs))\n",
    "#network_weights = initialise_weights(n_inputs, n_hidden_inputs, n_outputs)\n",
    "network_bias = np.array(initialise_bias(n_hidden_layer))\n",
    "\n",
    "print(\"Length of inputs\",len(filtered_images))\n",
    "#print(\"actual y\",input_y)\n",
    "print(\"input Weights\", len(input_weights))\n",
    "print(\"output Weights\", len(output_weights))\n",
    "print(\"Network Bias\", len(network_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "120\n",
      "Index:  0  Input:  [ 0.48689889  0.87345834]\n",
      "Index:  0  Target value:  0\n",
      "Index:  1  Input:  [ 0.99547416 -0.09503259]\n",
      "Index:  1  Target value:  1\n",
      "Index:  2  Input:  [ 0.66817981 -0.74399982]\n",
      "Index:  2  Target value:  1\n",
      "Index:  3  Input:  [ 0.99654419  0.08306432]\n",
      "Index:  3  Target value:  0\n",
      "Index:  4  Input:  [-0.72962975  0.6838424 ]\n",
      "Index:  4  Target value:  0\n",
      "Index:  5  Input:  [-0.17434003  0.98468551]\n",
      "Index:  5  Target value:  1\n",
      "Index:  6  Input:  [-0.40422617  0.91465907]\n",
      "Index:  6  Target value:  0\n",
      "Index:  7  Input:  [-0.03451603  0.99940414]\n",
      "Index:  7  Target value:  1\n",
      "Index:  8  Input:  [ 0.99652197  0.08333043]\n",
      "Index:  8  Target value:  1\n",
      "Index:  9  Input:  [-0.4812387   0.87658959]\n",
      "Index:  9  Target value:  0\n",
      "Index:  10  Input:  [-0.17222527  0.98505759]\n",
      "Index:  10  Target value:  0\n",
      "Index:  11  Input:  [ 0.19469947  0.98086295]\n",
      "Index:  11  Target value:  0\n",
      "Index:  12  Input:  [ 0.48120095  0.87661032]\n",
      "Index:  12  Target value:  0\n",
      "Index:  13  Input:  [-0.44670859  0.89467952]\n",
      "Index:  13  Target value:  1\n",
      "Index:  14  Input:  [-0.97183759  0.23565163]\n",
      "Index:  14  Target value:  0\n",
      "Index:  15  Input:  [ 0.98510517  0.17195291]\n",
      "Index:  15  Target value:  1\n",
      "Index:  16  Input:  [-0.92368007  0.38316462]\n",
      "Index:  16  Target value:  0\n",
      "Index:  17  Input:  [ 0.33071254  0.94373154]\n",
      "Index:  17  Target value:  0\n",
      "Index:  18  Input:  [ 0.56607385 -0.82435454]\n",
      "Index:  18  Target value:  1\n",
      "Index:  19  Input:  [ 0.52884735  0.84871696]\n",
      "Index:  19  Target value:  0\n",
      "Index:  20  Input:  [ 0.76914562  0.63907356]\n",
      "Index:  20  Target value:  0\n",
      "Index:  21  Input:  [ 0.99999944 -0.00105388]\n",
      "Index:  21  Target value:  1\n",
      "Index:  22  Input:  [ 0.17876266  0.98389223]\n",
      "Index:  22  Target value:  0\n",
      "Index:  23  Input:  [ 0.99493695  0.10050108]\n",
      "Index:  23  Target value:  1\n",
      "Index:  24  Input:  [ 0.96651498  0.25661019]\n",
      "Index:  24  Target value:  1\n",
      "Index:  25  Input:  [ 0.95744484 -0.28861633]\n",
      "Index:  25  Target value:  1\n",
      "Index:  26  Input:  [-0.92035764  0.39107775]\n",
      "Index:  26  Target value:  0\n",
      "Index:  27  Input:  [ 0.7865661  -0.61750609]\n",
      "Index:  27  Target value:  1\n",
      "Index:  28  Input:  [ 0.1433124  0.9896775]\n",
      "Index:  28  Target value:  0\n",
      "Index:  29  Input:  [-0.21340553 -0.97696371]\n",
      "Index:  29  Target value:  1\n",
      "Index:  30  Input:  [-0.52222962  0.85280491]\n",
      "Index:  30  Target value:  0\n",
      "Index:  31  Input:  [-0.42801171  0.90377319]\n",
      "Index:  31  Target value:  0\n",
      "Index:  32  Input:  [-0.96651561  0.25660784]\n",
      "Index:  32  Target value:  0\n",
      "Index:  33  Input:  [ 0.83450906 -0.55099421]\n",
      "Index:  33  Target value:  1\n",
      "Index:  34  Input:  [ 0.93598791 -0.35203214]\n",
      "Index:  34  Target value:  1\n",
      "Index:  35  Input:  [ 0.83477805 -0.5505866 ]\n",
      "Index:  35  Target value:  1\n",
      "Index:  36  Input:  [ 0.99261748  0.12128703]\n",
      "Index:  36  Target value:  0\n",
      "Index:  37  Input:  [ 0.98908998 -0.1473126 ]\n",
      "Index:  37  Target value:  1\n",
      "Index:  38  Input:  [ 0.98279473  0.18470118]\n",
      "Index:  38  Target value:  1\n",
      "Index:  39  Input:  [-0.96658814  0.25633448]\n",
      "Index:  39  Target value:  0\n",
      "Index:  40  Input:  [-0.65792672  0.75308195]\n",
      "Index:  40  Target value:  0\n",
      "Index:  41  Input:  [ 0.95201878  0.30603961]\n",
      "Index:  41  Target value:  0\n",
      "Index:  42  Input:  [ 0.01652508  0.99986345]\n",
      "Index:  42  Target value:  0\n",
      "Index:  43  Input:  [ 0.95824707  0.28594153]\n",
      "Index:  43  Target value:  0\n",
      "Index:  44  Input:  [ 0.03567925  0.99936329]\n",
      "Index:  44  Target value:  0\n",
      "Index:  45  Input:  [ 0.79265546  0.60966985]\n",
      "Index:  45  Target value:  0\n",
      "Index:  46  Input:  [-0.99748502  0.07087767]\n",
      "Index:  46  Target value:  0\n",
      "Index:  47  Input:  [ 0.99998258 -0.00590253]\n",
      "Index:  47  Target value:  1\n",
      "Index:  48  Input:  [-0.49609224  0.86826983]\n",
      "Index:  48  Target value:  0\n",
      "Index:  49  Input:  [ 0.92848697  0.37136498]\n",
      "Index:  49  Target value:  0\n",
      "Index:  50  Input:  [-0.74384634  0.66835067]\n",
      "Index:  50  Target value:  0\n",
      "Index:  51  Input:  [ 0.57080684 -0.82108438]\n",
      "Index:  51  Target value:  1\n",
      "Index:  52  Input:  [ 0.99704607  0.07680583]\n",
      "Index:  52  Target value:  0\n",
      "Index:  53  Input:  [ 0.21257245  0.97714531]\n",
      "Index:  53  Target value:  0\n",
      "Index:  54  Input:  [ 0.98639962  0.16436479]\n",
      "Index:  54  Target value:  1\n",
      "Index:  55  Input:  [ 0.96206215  0.27283039]\n",
      "Index:  55  Target value:  1\n",
      "Index:  56  Input:  [ 0.84133562 -0.54051306]\n",
      "Index:  56  Target value:  1\n",
      "Index:  57  Input:  [ 0.70736473  0.70684874]\n",
      "Index:  57  Target value:  1\n",
      "Index:  58  Input:  [ 0.55647039  0.83086744]\n",
      "Index:  58  Target value:  1\n",
      "Index:  59  Input:  [ 0.87225248 -0.48905584]\n",
      "Index:  59  Target value:  1\n",
      "Index:  60  Input:  [ 0.56477223  0.82524683]\n",
      "Index:  60  Target value:  0\n",
      "Index:  61  Input:  [ 0.99076237 -0.13560943]\n",
      "Index:  61  Target value:  1\n",
      "Index:  62  Input:  [ 0.05456579 -0.99851018]\n",
      "Index:  62  Target value:  1\n",
      "Index:  63  Input:  [ 0.7933292  -0.60879289]\n",
      "Index:  63  Target value:  1\n",
      "Index:  64  Input:  [ 0.98082441  0.19489351]\n",
      "Index:  64  Target value:  1\n",
      "Index:  65  Input:  [ 0.72775399  0.68583827]\n",
      "Index:  65  Target value:  1\n",
      "Index:  66  Input:  [-0.05056437  0.9987208 ]\n",
      "Index:  66  Target value:  0\n",
      "Index:  67  Input:  [-0.02790785  0.9996105 ]\n",
      "Index:  67  Target value:  0\n",
      "Index:  68  Input:  [ 0.91372597 -0.40633097]\n",
      "Index:  68  Target value:  1\n",
      "Index:  69  Input:  [-0.98718141  0.15960219]\n",
      "Index:  69  Target value:  0\n",
      "Index:  70  Input:  [-0.4043167   0.91461905]\n",
      "Index:  70  Target value:  0\n",
      "Index:  71  Input:  [-0.27023203  0.96279523]\n",
      "Index:  71  Target value:  1\n",
      "Index:  72  Input:  [ 0.66099702  0.75038853]\n",
      "Index:  72  Target value:  0\n",
      "Index:  73  Input:  [ 0.98923656  0.14632509]\n",
      "Index:  73  Target value:  1\n",
      "Index:  74  Input:  [ 0.16912402  0.98559478]\n",
      "Index:  74  Target value:  1\n",
      "Index:  75  Input:  [ 0.98430339  0.17648466]\n",
      "Index:  75  Target value:  1\n",
      "Index:  76  Input:  [ 0.98586709 -0.16752934]\n",
      "Index:  76  Target value:  1\n",
      "Index:  77  Input:  [-0.02988516  0.99955334]\n",
      "Index:  77  Target value:  0\n",
      "Index:  78  Input:  [-0.33784849  0.94120051]\n",
      "Index:  78  Target value:  0\n",
      "Index:  79  Input:  [ 0.31391374  0.94945151]\n",
      "Index:  79  Target value:  0\n",
      "Index:  80  Input:  [-0.13487919  0.99086205]\n",
      "Index:  80  Target value:  0\n",
      "Index:  81  Input:  [ 0.80318377 -0.59573134]\n",
      "Index:  81  Target value:  1\n",
      "Index:  82  Input:  [-0.99486586  0.10120234]\n",
      "Index:  82  Target value:  0\n",
      "Index:  83  Input:  [ 0.97589661  0.21823336]\n",
      "Index:  83  Target value:  1\n",
      "Index:  84  Input:  [ 0.59921092  0.8005912 ]\n",
      "Index:  84  Target value:  0\n",
      "Index:  85  Input:  [ 0.02315858  0.9997318 ]\n",
      "Index:  85  Target value:  0\n",
      "Index:  86  Input:  [ 0.9314557  -0.36385476]\n",
      "Index:  86  Target value:  1\n",
      "Index:  87  Input:  [ 0.41897574  0.90799743]\n",
      "Index:  87  Target value:  0\n",
      "Index:  88  Input:  [ 0.92876325  0.37067348]\n",
      "Index:  88  Target value:  0\n",
      "Index:  89  Input:  [ 0.90303602 -0.42956483]\n",
      "Index:  89  Target value:  1\n",
      "Index:  90  Input:  [ 0.9294835  0.3688637]\n",
      "Index:  90  Target value:  0\n",
      "Index:  91  Input:  [ 0.99936025  0.03576434]\n",
      "Index:  91  Target value:  1\n",
      "Index:  92  Input:  [-0.99655695  0.08291103]\n",
      "Index:  92  Target value:  0\n",
      "Index:  93  Input:  [-0.79189118  0.61066224]\n",
      "Index:  93  Target value:  0\n",
      "Index:  94  Input:  [ 0.98953195  0.14431397]\n",
      "Index:  94  Target value:  1\n",
      "Index:  95  Input:  [ 0.96858873  0.24866818]\n",
      "Index:  95  Target value:  0\n",
      "Index:  96  Input:  [ 0.94737417 -0.3201284 ]\n",
      "Index:  96  Target value:  1\n",
      "Index:  97  Input:  [ 0.88709583 -0.4615853 ]\n",
      "Index:  97  Target value:  1\n",
      "Index:  98  Input:  [ 0.9754861   0.22006105]\n",
      "Index:  98  Target value:  1\n",
      "Index:  99  Input:  [ 0.99988059 -0.01545362]\n",
      "Index:  99  Target value:  1\n",
      "Index:  100  Input:  [ 0.99508722  0.09900215]\n",
      "Index:  100  Target value:  1\n",
      "Index:  101  Input:  [ 0.99784625  0.06559614]\n",
      "Index:  101  Target value:  0\n",
      "Index:  102  Input:  [ 0.98370012 -0.17981677]\n",
      "Index:  102  Target value:  1\n",
      "Index:  103  Input:  [ 0.33907863 -0.94075804]\n",
      "Index:  103  Target value:  1\n",
      "Index:  104  Input:  [ 0.82584758 -0.56389341]\n",
      "Index:  104  Target value:  1\n",
      "Index:  105  Input:  [-0.67788564  0.73516737]\n",
      "Index:  105  Target value:  0\n",
      "Index:  106  Input:  [ 0.93484011  0.35506896]\n",
      "Index:  106  Target value:  0\n",
      "Index:  107  Input:  [ 0.98287945  0.18424979]\n",
      "Index:  107  Target value:  1\n",
      "Index:  108  Input:  [-0.1547802   0.98794893]\n",
      "Index:  108  Target value:  1\n",
      "Index:  109  Input:  [ 0.90763117 -0.41976858]\n",
      "Index:  109  Target value:  1\n",
      "Index:  110  Input:  [ 0.02706176  0.99963376]\n",
      "Index:  110  Target value:  0\n",
      "Index:  111  Input:  [ 0.33102167  0.94362315]\n",
      "Index:  111  Target value:  0\n",
      "Index:  112  Input:  [ 0.79635695  0.60482692]\n",
      "Index:  112  Target value:  0\n",
      "Index:  113  Input:  [ 0.98444955  0.17566756]\n",
      "Index:  113  Target value:  1\n",
      "Index:  114  Input:  [ 0.96221356 -0.27229592]\n",
      "Index:  114  Target value:  1\n",
      "Index:  115  Input:  [ 0.83369257  0.55222885]\n",
      "Index:  115  Target value:  0\n",
      "Index:  116  Input:  [ 0.89820619  0.43957438]\n",
      "Index:  116  Target value:  0\n",
      "Index:  117  Input:  [ 0.99813018 -0.06112403]\n",
      "Index:  117  Target value:  1\n",
      "Index:  118  Input:  [ 0.98428596  0.17658184]\n",
      "Index:  118  Target value:  1\n",
      "Index:  119  Input:  [ 0.96764182 -0.25232779]\n",
      "Index:  119  Target value:  1\n"
     ]
    }
   ],
   "source": [
    "## TEST MODEL\n",
    "inputs = preprocessing.normalize(test_X)\n",
    "target = test_y\n",
    "target = np.array(target)\n",
    "print(len(inputs))\n",
    "print(len(target))\n",
    "#tol=1e-7\n",
    "#maxrounds=1000\n",
    "#iter=0\n",
    "error = 99.0\n",
    "#while abs(error) > tol:\n",
    "error_res = []\n",
    "result = []\n",
    "#result = np.array(result)\n",
    "\n",
    "for i in range(len(inputs)):\n",
    "    print (\"Index: \",i, \" Input: \", inputs[i])\n",
    "    print (\"Index: \",i,\" Target value: \", target[i])\n",
    "        \n",
    "    ### START OF FORWARD PROPAGATION FUNCTION CALLS\n",
    "    # test get_sigmoid_output \n",
    "    hidden_layer = get_sigmoid_output(Weights1, inputs[i], network_bias[0])\n",
    "    ##print (\"hidden_layer result:\", hidden_layer)\n",
    "        \n",
    "    # test get_output\n",
    "    output = get_output(hidden_layer, Weights2, network_bias[1])\n",
    "    #  print (\"output:\", output)\n",
    "    result.append(output)\n",
    "        \n",
    "    # call error function\n",
    "    error = get_error(target[i], output)\n",
    "    error_res.append(error)\n",
    "    #print(\"error:\", error)\n",
    "        \n",
    "    # END OF FORWARD PROPAGATION FUNCTION CALLS\n",
    "result = np.array(result)  \n",
    "error_res = np.array(error_res)\n",
    "target = np.array(target)\n",
    "#print(\"Target:\", target)        \n",
    "#print(\"Results: \", result)\n",
    "#print(\"Error:\", error_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "120\n",
      "1e-07\n",
      "True Negative:  0  -  [[ 0.99848159]]\n",
      "False Positive:  1  -  [[ 0.99856238]]\n",
      "False Positive:  1  -  [[ 0.99862]]\n",
      "True Negative:  0  -  [[ 0.99856124]]\n",
      "True Negative:  0  -  [[ 0.6886039]]\n",
      "False Positive:  1  -  [[ 0.59181311]]\n",
      "True Negative:  0  -  [[ 0.60250123]]\n",
      "False Positive:  1  -  [[ 0.77430094]]\n",
      "False Positive:  1  -  [[ 0.99856124]]\n",
      "True Negative:  0  -  [[ 0.62771788]]\n",
      "True Negative:  0  -  [[ 0.59302581]]\n",
      "True Negative:  0  -  [[ 0.99246221]]\n",
      "True Negative:  0  -  [[ 0.99847377]]\n",
      "False Positive:  1  -  [[ 0.61642911]]\n",
      "True Negative:  0  -  [[ 0.71331424]]\n",
      "False Positive:  1  -  [[ 0.99856125]]\n",
      "True Negative:  0  -  [[ 0.7100974]]\n",
      "True Negative:  0  -  [[ 0.99779114]]\n",
      "False Positive:  1  -  [[ 0.99866076]]\n",
      "True Negative:  0  -  [[ 0.99852397]]\n",
      "True Negative:  0  -  [[ 0.99856832]]\n",
      "False Positive:  1  -  [[ 0.99856157]]\n",
      "True Negative:  0  -  [[ 0.99052377]]\n",
      "False Positive:  1  -  [[ 0.99856121]]\n",
      "False Positive:  1  -  [[ 0.99856161]]\n",
      "False Positive:  1  -  [[ 0.99856608]]\n",
      "True Negative:  0  -  [[ 0.70985577]]\n",
      "False Positive:  1  -  [[ 0.99858971]]\n",
      "True Negative:  0  -  [[ 0.98335203]]\n",
      "False Positive:  1  -  [[ 0.98975155]]\n",
      "True Negative:  0  -  [[ 0.6405625]]\n",
      "True Negative:  0  -  [[ 0.61026205]]\n",
      "True Negative:  0  -  [[ 0.71297741]]\n",
      "False Positive:  1  -  [[ 0.99858122]]\n",
      "False Positive:  1  -  [[ 0.99856821]]\n",
      "False Positive:  1  -  [[ 0.99858118]]\n",
      "True Negative:  0  -  [[ 0.9985612]]\n",
      "False Positive:  1  -  [[ 0.99856307]]\n",
      "False Positive:  1  -  [[ 0.99856128]]\n",
      "True Negative:  0  -  [[ 0.71298201]]\n",
      "True Negative:  0  -  [[ 0.67543556]]\n",
      "True Negative:  0  -  [[ 0.99856198]]\n",
      "True Negative:  0  -  [[ 0.86933663]]\n",
      "True Negative:  0  -  [[ 0.99856181]]\n",
      "True Negative:  0  -  [[ 0.89955229]]\n",
      "True Negative:  0  -  [[ 0.99856762]]\n",
      "True Negative:  0  -  [[ 0.71505877]]\n",
      "False Positive:  1  -  [[ 0.9985616]]\n",
      "True Negative:  0  -  [[ 0.6324628]]\n",
      "True Negative:  0  -  [[ 0.99856269]]\n",
      "True Negative:  0  -  [[ 0.69081938]]\n",
      "False Positive:  1  -  [[ 0.99865851]]\n",
      "True Negative:  0  -  [[ 0.99856125]]\n",
      "True Negative:  0  -  [[ 0.99404327]]\n",
      "False Positive:  1  -  [[ 0.99856124]]\n",
      "False Positive:  1  -  [[ 0.99856172]]\n",
      "False Positive:  1  -  [[ 0.99858016]]\n",
      "False Positive:  1  -  [[ 0.99856893]]\n",
      "False Positive:  1  -  [[ 0.99854114]]\n",
      "False Positive:  1  -  [[ 0.9985757]]\n",
      "True Negative:  0  -  [[ 0.99854511]]\n",
      "False Positive:  1  -  [[ 0.9985629]]\n",
      "False Positive:  1  -  [[ 0.9989278]]\n",
      "False Positive:  1  -  [[ 0.9985884]]\n",
      "False Positive:  1  -  [[ 0.99856131]]\n",
      "False Positive:  1  -  [[ 0.99856901]]\n",
      "True Negative:  0  -  [[ 0.74394892]]\n",
      "True Negative:  0  -  [[ 0.78702522]]\n",
      "False Positive:  1  -  [[ 0.9985706]]\n",
      "True Negative:  0  -  [[ 0.7142958]]\n",
      "True Negative:  0  -  [[ 0.6025304]]\n",
      "False Positive:  1  -  [[ 0.57164922]]\n",
      "True Negative:  0  -  [[ 0.99856696]]\n",
      "False Positive:  1  -  [[ 0.99856121]]\n",
      "False Positive:  1  -  [[ 0.98902968]]\n",
      "False Positive:  1  -  [[ 0.99856126]]\n",
      "False Positive:  1  -  [[ 0.99856338]]\n",
      "True Negative:  0  -  [[ 0.78321189]]\n",
      "True Negative:  0  -  [[ 0.58299265]]\n",
      "True Negative:  0  -  [[ 0.99758638]]\n",
      "True Negative:  0  -  [[ 0.62186106]]\n",
      "False Positive:  1  -  [[ 0.99858656]]\n",
      "True Negative:  0  -  [[ 0.71483776]]\n",
      "False Positive:  1  -  [[ 0.9985614]]\n",
      "True Negative:  0  -  [[ 0.99855715]]\n",
      "True Negative:  0  -  [[ 0.88030617]]\n",
      "False Positive:  1  -  [[ 0.99856868]]\n",
      "True Negative:  0  -  [[ 0.99833685]]\n",
      "True Negative:  0  -  [[ 0.99856269]]\n",
      "False Positive:  1  -  [[ 0.99857183]]\n",
      "True Negative:  0  -  [[ 0.99856266]]\n",
      "False Positive:  1  -  [[ 0.99856139]]\n",
      "True Negative:  0  -  [[ 0.71497565]]\n",
      "True Negative:  0  -  [[ 0.69744366]]\n",
      "False Positive:  1  -  [[ 0.99856121]]\n",
      "True Negative:  0  -  [[ 0.99856156]]\n",
      "False Positive:  1  -  [[ 0.99856706]]\n",
      "False Positive:  1  -  [[ 0.99857377]]\n",
      "False Positive:  1  -  [[ 0.99856141]]\n",
      "False Positive:  1  -  [[ 0.99856167]]\n",
      "False Positive:  1  -  [[ 0.99856122]]\n",
      "True Negative:  0  -  [[ 0.99856128]]\n",
      "False Positive:  1  -  [[ 0.99856359]]\n",
      "False Positive:  1  -  [[ 0.99881595]]\n",
      "False Positive:  1  -  [[ 0.99858263]]\n",
      "True Negative:  0  -  [[ 0.67945128]]\n",
      "True Negative:  0  -  [[ 0.99856249]]\n",
      "False Positive:  1  -  [[ 0.99856128]]\n",
      "False Positive:  1  -  [[ 0.60468412]]\n",
      "False Positive:  1  -  [[ 0.9985713]]\n",
      "True Negative:  0  -  [[ 0.88651921]]\n",
      "True Negative:  0  -  [[ 0.99779446]]\n",
      "True Negative:  0  -  [[ 0.9985675]]\n",
      "False Positive:  1  -  [[ 0.99856126]]\n",
      "False Positive:  1  -  [[ 0.99856562]]\n",
      "True Negative:  0  -  [[ 0.99856615]]\n",
      "True Negative:  0  -  [[ 0.99856373]]\n",
      "False Positive:  1  -  [[ 0.99856203]]\n",
      "False Positive:  1  -  [[ 0.99856126]]\n",
      "False Positive:  1  -  [[ 0.99856511]]\n",
      "True Positive:  0\n",
      "True Negative:  60\n",
      "False Positive:  60\n",
      "False Negative:  0\n"
     ]
    }
   ],
   "source": [
    "# calculate the accuracy of the NN\n",
    "tol=1e-7\n",
    "print(len(target))\n",
    "print(len(result))\n",
    "print(tol)\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "for i in range(len(target)):\n",
    "        \n",
    "        if (target[i] == 1 and target[i]-result[i] <= tol):\n",
    "            TP = TP + 1\n",
    "            print(\"True Positive: \", target[i], \" - \", result[i])\n",
    "\n",
    "        if (target[i] == 0 and target[i]-result[i] <= tol):\n",
    "            TN = TN + 1\n",
    "            print(\"True Negative: \",target[i], \" - \", result[i])\n",
    "            \n",
    "        if (target[i] == 1 and target[i]-result[i] > tol):\n",
    "            FP = FP + 1\n",
    "            print(\"False Positive: \",target[i], \" - \", result[i])\n",
    "            \n",
    "        if (target[i] == 0 and target[i]-result[i] > tol):\n",
    "            FN = FN + 1\n",
    "            print(\"False Negative: \",target[i], \" - \", result[i])\n",
    "        \n",
    "print(\"True Positive: \", TP)\n",
    "print(\"True Negative: \", TN)\n",
    "print(\"False Positive: \", FP)\n",
    "print(\"False Negative: \", FN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
