{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mnist import MNIST\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the weights for the network based on the input layers, the number of hidden layers, the number of output layers\n",
    "#reference for above https://www.coursera.org/learn/deep-neural-network/lecture/RwqYe/weight-initialization-for-deep-networks\n",
    "def initialise_input_weights(n_inputs, n_hidden_inputs):\n",
    " hidden_layer_weights = list()\n",
    " for i in range(n_hidden_inputs):\n",
    "  weight = np.random.randn(n_inputs)*np.sqrt(1/(n_inputs)**(n_hidden_inputs-1))\n",
    "  hidden_layer_weights.append(weight)\n",
    "   \n",
    " input_weights = np.array([hidden_layer_weights])\n",
    " input_weights = np.reshape(input_weights, (n_inputs, n_hidden_inputs))\n",
    " return input_weights; \n",
    "\n",
    "def initialise_output_weights(n_hidden_inputs,n_outputs):\n",
    " output_layer_weights = list()\n",
    " for i in range(n_outputs):\n",
    "  weight = np.random.randn(n_outputs)*np.sqrt(1/(n_outputs)**(n_hidden_inputs-1))\n",
    "  output_layer_weights.append(weight) \n",
    "   \n",
    " output_weights = np.array([output_layer_weights])\n",
    " #if n_outputs == 1:\n",
    "  #output_weights = np.array([output_layer_weights])\n",
    " #elif n_outputs > 1:\n",
    "  #output_weights = np.array([output_layer_weights])  \n",
    "  #output_weights = np.reshape(output_weights, (n_hidden_inputs,n_outputs))   \n",
    "\n",
    " return output_weights;\n",
    "\n",
    "#initialise the bias for the network based on the number of hidden layers and the output layer bias\n",
    "def initialise_bias(n_hidden_layer):\n",
    " hidden_layer_bias = list()    \n",
    " for i in range(n_hidden_layer):\n",
    "  bias = np.random.random(1)[0]\n",
    "  hidden_layer_bias.append(bias)\n",
    " \n",
    " output_layer_bias = [np.random.random(1)[0]]\n",
    " network_bias = [[hidden_layer_bias],[output_layer_bias]]\n",
    " return network_bias;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Weights:  [[-0.07223614  0.68299066]\n",
      " [ 0.05021177  0.33873961]\n",
      " [ 0.37491764  0.185205  ]\n",
      " [ 0.18137765  0.05359783]]\n",
      "Output Weights:  [[[-0.22632591  0.02085877  0.42755861 -0.48800597]\n",
      "  [ 0.80906297  0.47078369  0.06190929  0.68706746]\n",
      "  [ 0.87608869  0.00583639  0.35673269  0.99378664]\n",
      "  [ 0.27084481  0.13703785  0.35662091 -0.30558057]]]\n",
      "Bias: [[[0.53402582479343974]], [[0.81525647518931654]]]\n"
     ]
    }
   ],
   "source": [
    "# Testing weight intialisation\n",
    "input_weights = initialise_input_weights(4,2)\n",
    "print(\"Input Weights: \",input_weights)\n",
    "weights = initialise_output_weights(2,4)\n",
    "print(\"Output Weights: \",weights)\n",
    "\n",
    "bias = initialise_bias(1)\n",
    "print(\"Bias:\", bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "# g(z) = 1/ 1 + e^-z\n",
    "def sigmoid(z):\n",
    " g = 1/(1 + np.exp(-z))\n",
    " return g;\n",
    "\n",
    "# --------------- FORWARD PROPAGATION  --------------------------\n",
    "# return the sigmoid_input_act - sigmoid function sum of the input layer activation \n",
    "# a_n^2 = f(W_n1^1 x1 + W_n2^1 x2 + W_n3^1 x3 +b_n^1 )\n",
    "def get_input_layer_activation(input, input_weights, input_bias):\n",
    " print(\"Input shape \",np.shape(input))\n",
    " print(\"Input weight shape \",np.shape(input))\n",
    " hidden_layer = (input * input_weights)\n",
    " #print(\"input_layer_activation: \",input_layer_activation)\n",
    " hidden_layer = np.sum(hidden_layer, axis = 1) + input_bias * 1\n",
    " #print(\"Sum of Hidden Layer activation: \", hidden_layer_activation)\n",
    " hidden_layer = sigmoid(hidden_layer)\n",
    " #print(\"Sigmoid function of Sum of Hidden Layer activation: \", sigmoid_input_activation)\n",
    " return hidden_layer;\n",
    "\n",
    "# get output layer activation for hidden layer\n",
    "# a1_3\n",
    "def get_output_layer_activation(hidden_layer, output_weights, output_bias):\n",
    " activation_output = (hidden_layer * output_weights)\n",
    " activation_output = sigmoid(np.sum(activation_output) + output_bias * 1 )\n",
    " #print(\"Activation Output: \",activation_output)   \n",
    " return activation_output;\n",
    " \n",
    "def forward_propagation(input, input_weights, output_weights, input_bias, output_bias):\n",
    " sigmoid_input_activation = get_input_layer_activation(input, input_weights, input_bias)\n",
    " activation_output = get_output_layer_activation(sigmoid_input_activation, output_weights, output_bias)\n",
    " #print(\"Forward Propagation Activation Output: \",activation_output)    \n",
    " return activation_output;   \n",
    "\n",
    "# Calculate the Total Error Sum of Squared Errors = âˆ‘ 1/2(Y-YP)^2 \n",
    "#E_total = 1/2(target_01 - out_01)^2 \n",
    "# sum of squared errors of prediction\n",
    "def calc_error(actual_y, target):\n",
    " error = 1/2 * np.power((actual_y - target), 2)\n",
    " return error;\n",
    "\n",
    "# If there is more than 1 node in the output layer, sum up the calc error\n",
    "def calc_total_error(actual_y, target):\n",
    " total_error = 0\n",
    " total_error += calc_error(actual_y, target)\n",
    " return total_error;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "total_error  = calc_total_error(1, 0)\n",
    "print(total_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FUNCTIONS FOR BACK PROPAGATION OF OUTPUT\n",
    "# calculate derivative of error at output layer\n",
    "\n",
    "# Derivitive of error with reference to output\n",
    "# deriv_wrt_out = -(target - output)\n",
    "# change above to function\n",
    "def deltaErr_wrt_out(target, output):\n",
    " result = -(target - output)\n",
    " print(\"Derivitive of error with reference to output:\", result)\n",
    " return result;  \n",
    "\n",
    "# calculate the derivation of the error output wrt the net\n",
    "# derivout_wrt_net = output*(1-output)\n",
    "# change above to function\n",
    "def deltaOut_wrt_net(output):\n",
    " result = output * (1 - output)\n",
    " print(\"Derivitive of error output with reference to net output:\", result)\n",
    " return result;   \n",
    "\n",
    "# calculate derivative of error wrt to output layer weight OLW_Deriv\n",
    "# Output Layer Weight Derivitive\n",
    "def deltaErr_ow(deriv_wrt_out, derivout_wrt_net, activation):\n",
    " OLW_Deriv = deriv_wrt_out * derivout_wrt_net * activation\n",
    " print(\"Derivative of error with reference to output layer weight:\", OLW_Deriv)\n",
    " return OLW_Deriv;\n",
    "    \n",
    "# FUNCTIONS FOR BACK PROPAGATION OF HIDDEN LAYER\n",
    "# calculate derivative of error at hidden layer\n",
    "# deriv_out_wrt_hL =  Weights2 * deriv_wrt_out *derivout_wrt_net\n",
    "# print (deriv_out_wrt_hL)\n",
    "# convert above to function\n",
    "def deltaOut_hL(deriv_wrt_out, derivout_wrt_net, output_weights):\n",
    " deriv_out_wrt_hL = deriv_wrt_out * derivout_wrt_net * output_weights\n",
    " return deriv_out_wrt_hL;\n",
    "\n",
    "# derivitive output in relation to net of hidden layer activation\n",
    "# deriv_out_wrt_nethL = activation*(1-activation)\n",
    "# convert above to function\n",
    "def deltaOut_netHL(activation):\n",
    " activation = activation * (1 - activation)\n",
    " return activation;\n",
    "\n",
    "# Derivitive in relation to input_weights\n",
    "# deriv_wrt_wi = deriv_out_wrt_hL*deriv_out_wrt_nethL*Weights1\n",
    "# convert above to function\n",
    "def deltaErr_wi(deriv_out_wrt_hL, deriv_out_wrt_nethL, input_weights):\n",
    " deriv_wrt_wi = deriv_out_wrt_hL * deriv_out_wrt_nethL * input_weights\n",
    " return deriv_wrt_wi;\n",
    "\n",
    "# convert the above to a function\n",
    "def calc_adjusted_weights(W, deriv):\n",
    " W = W - (alpha * deriv)\n",
    " return W;\n",
    "\n",
    "# delta error with reference to output\n",
    "def delta_error_wrt_output(output, hidden_layer, target):\n",
    " deltaErr_out = deltaErr_wrt_out(target, output)\n",
    " deltaOut_net = deltaOut_wrt_net(output)\n",
    " deltaErrtot_ow = deltaErr_ow(deltaErr_out, deltaOut_net, hidden_layer)\n",
    " print(\"Delta Error with reference to output\", deltaErrtot_ow)\n",
    " return deltaErrtot_ow, deltaErr_out, deltaOut_net;\n",
    "\n",
    " \n",
    "# Delta Error with reference to input\n",
    "def delta_error_wrt_input(hidden_layer, network_bias, deltaErr_out, deltaOut_net):\n",
    " deltaErrOut_hL = deltaOut_hL(deltaErr_out, deltaOut_net, network_bias[1])\n",
    " deltaErrOut_netHL = deltaOut_netHL(hidden_layer)\n",
    " deltaErrH_wi = deltaErr_wi(deltaErrOut_hL, deltaErrOut_netHL, network_bias[0])\n",
    " print(\"Delta Error with reference to input\", deltaErrH_wi)\n",
    " return deltaErrH_wi;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 2) (280,)\n",
      "(120, 2) (120,)\n"
     ]
    }
   ],
   "source": [
    " # Reading in the the small data file for the train/test datasets   \n",
    "inputDataFrame = pd.read_csv(\"moons400.csv\")  # instance variable unique to each instance\n",
    "y = inputDataFrame['Class'].values   \n",
    "\n",
    "#split up the dataset into training and test split 70/30 for training/test\n",
    "train_X, test_X, train_y, test_y = train_test_split(inputDataFrame, y, test_size=0.30)\n",
    "\n",
    "del train_X['Class']    # drop the 'Class' column from the Train and test dataframe\n",
    "del test_X['Class']\n",
    "print(train_X.shape, train_y.shape)\n",
    "print(test_X.shape, test_y.shape)\n",
    "\n",
    "(nsamples, nattribs) = np.shape(train_X)\n",
    "input_X = train_X\n",
    "input_y = train_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: samples = 280 , attribs = 2\n",
      "Length of inputs 280\n",
      "input Weights 2\n",
      "[[ 0.15610386 -0.94953597]\n",
      " [-0.57003457  0.93783941]]\n",
      "output Weights 1\n",
      "Network Bias 2\n"
     ]
    }
   ],
   "source": [
    "# set up weights and biases \n",
    "(train_samples, train_shape) = np.shape(inputs)\n",
    "print (\"train: samples =\", train_samples, \", attribs =\", train_shape)\n",
    "\n",
    "# Test weights and bias initialisation based on network inputs, hidden layers, and outputs\n",
    "# first line of moons.csv\n",
    "#input_X =[[2.07106946, 0.41152931]]\n",
    "\n",
    "#(nsamples, nattribs) = np.shape(input_X)\n",
    "n_inputs = train_shape\n",
    "\n",
    "n_hidden_layer = 1\n",
    "n_hidden_inputs = 2\n",
    "n_outputs = 1\n",
    "\n",
    "# normalise training data\n",
    "# rescale the inputs using normalization \n",
    "# mnist_train = preprocessing.normalize(filtered_images)\n",
    "#print(\"normalised inputs\",inputs)\n",
    "\n",
    "Weights1 = np.array(initialise_input_weights(n_inputs, n_hidden_inputs), dtype=np.float64)\n",
    "Weights2 = np.array(initialise_output_weights(n_hidden_inputs, n_outputs), dtype=np.float64)\n",
    "#network_weights = initialise_weights(n_inputs, n_hidden_inputs, n_outputs)\n",
    "bias = np.array(initialise_bias(n_hidden_layer), dtype=np.float64)\n",
    "\n",
    "print(\"Length of inputs\",len(inputs))\n",
    "#print(\"actual y\",input_y)\n",
    "print(\"input Weights\", len(Weights1))\n",
    "print(Weights1)\n",
    "print(\"output Weights\", len(Weights2))\n",
    "print(\"Network Bias\", len(bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test weights and bias initialisation based on network inputs, hidden layers, and outputs\n",
    "# Number of input nodes, number of hidden nodes, number of hidden layers and number of output nodes\n",
    "n_inputs = nattribs\n",
    "n_hidden_layer = 1\n",
    "n_hidden_inputs = 2\n",
    "n_outputs = 1\n",
    "\n",
    "# rescale the inputs using normalization \n",
    "inputs = preprocessing.normalize(input_X)\n",
    "\n",
    "input_weights = np.array(initialise_input_weights(n_inputs, n_hidden_inputs), dtype=np.float64)\n",
    "output_weights = np.array(initialise_output_weights(n_hidden_inputs, n_outputs), dtype=np.float64)\n",
    "network_bias = np.array(initialise_bias(n_hidden_layer), dtype=np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ---- Train details ---- \n",
      "Length of inputs 280\n",
      "Input Weights [[ 0.25922157 -0.88883551]\n",
      " [-0.48035078 -0.78429056]]\n",
      "Output Weights [[[-1.41773504]]]\n",
      "Network Bias [[[ 0.72454061]]\n",
      "\n",
      " [[ 0.16372775]]]\n"
     ]
    }
   ],
   "source": [
    "# Test weight setup\n",
    "print(\" ---- Train details ---- \")\n",
    "print(\"Length of inputs\",len(inputs))\n",
    "print(\"Input Weights\", input_weights)\n",
    "print(\"Output Weights\", output_weights)\n",
    "print(\"Network Bias\", network_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Original Functions\n",
    "# FORWARD PROPAGATION USING FUNCTIONS\n",
    "# do the above using a function\n",
    "# convert calculations to function for hidden layer\n",
    "def get_sigmoid_output(weights, input, bias):\n",
    "    hidden_layer = input * weights \n",
    "    hidden_layer = np.sum(hidden_layer, axis=1) + bias\n",
    "    hidden_layer = 1/(1+np.exp(-hidden_layer))\n",
    "    return hidden_layer;\n",
    "\n",
    "def get_output(sigmoid_out, weights, bias):\n",
    "    output = (sigmoid_out*weights)\n",
    "    output = 1/(1+np.exp(-(np.sum(output)+bias)))\n",
    "    return output;\n",
    "\n",
    "# get the error \n",
    "# error_o = (0.5*(target - output)**2)\n",
    "# print(error_o)\n",
    "\n",
    "#convert to a function\n",
    "# I think this needs to change to accept a numpy array as well\n",
    "# we should end up with a data frame we can plot against the number of executions\n",
    "def get_error(t, o):\n",
    "    error_o = (0.5*(t - o)**2)\n",
    "    return error_o;\n",
    "# FUNCTIONS FOR BACK PROPAGATION OF OUTPUT\n",
    "# calculate derivative of error at output layer\n",
    "\n",
    "# deriv_wrt_out = -(target - output)\n",
    "# change above to function\n",
    "def deltaErr_wrt_out(targ, outp):\n",
    "    result = -(targ - outp)\n",
    "    return result;  \n",
    "\n",
    "# calculate the derivation of the error output wrt the net\n",
    "# derivout_wrt_net = output*(1-output)\n",
    "# change above to function\n",
    "def deltaOut_wrt_net(outp):\n",
    "    result = outp*(1-outp)\n",
    "    return result;   \n",
    "\n",
    "# change above to function\n",
    "# calculate derivative of error wrt to output layer weight OLW_Deriv\n",
    "def deltaErr_ow(deriv_wrt_out, derivout_wrt_net, activation):\n",
    "    OLW_Deriv = deriv_wrt_out*derivout_wrt_net*activation\n",
    "   # print(OLW_Deriv)\n",
    "    return OLW_Deriv;\n",
    "# FUNCTIONS FOR BACK PROPAGATION OF HIDDEN LAYER\n",
    "# calculate derivative of error at hidden layer\n",
    "\n",
    "# deriv_out_wrt_hL =  Weights2 * deriv_wrt_out *derivout_wrt_net\n",
    "# print (deriv_out_wrt_hL)\n",
    "# convert above to function\n",
    "def deltaOut_hL(deriv_wrt_out, derivout_wrt_net, weights):\n",
    "    deriv_out_wrt_hL = deriv_wrt_out *derivout_wrt_net *  weights\n",
    "    return deriv_out_wrt_hL;\n",
    "\n",
    "# deriv_out_wrt_nethL = activation*(1-activation)\n",
    "# convert above to function\n",
    "def deltaOut_netHL(activation):\n",
    "    activation = activation*(1-activation)\n",
    "    return activation;\n",
    "\n",
    "# deriv_wrt_wi = deriv_out_wrt_hL*deriv_out_wrt_nethL*Weights1\n",
    "# convert above to function\n",
    "def deltaErr_wi(deriv_out_wrt_hL, deriv_out_wrt_nethL, weights):\n",
    "    deriv_wrt_wi = deriv_out_wrt_hL*deriv_out_wrt_nethL*weights\n",
    "    return deriv_wrt_wi;\n",
    "\n",
    "# convert the above to a function\n",
    "def calc_adjusted_weights(W, deriv):\n",
    "    W = W - (alpha*deriv)\n",
    "    return W;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-21 14:32:00.282103\n",
      "\n",
      "Finished after  3001  error = [[ 0.12380719]] target= 1 , output= [[ 0.50239134]] input final= [ 0.9160975  -0.40095557]\n",
      "2018-02-21 14:32:36.562047\n",
      "Weights1 adjusted: [[[ 0.00624119 -0.00336873]\n",
      "  [-0.01156525 -0.0029725 ]]]\n",
      "Weights2 adjusted: [[[-4.92913402  4.69019771]]]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.01\n",
    "#TRAIN MODEL\n",
    "print(datetime.datetime.now())\n",
    "threshold=1e-5\n",
    "maxrounds=3000\n",
    "iter=0\n",
    "error = 99.0\n",
    "while abs(error) > threshold:\n",
    "    for i in range(len(inputs)):\n",
    "        #inputs, input_y, input_weights, output_weights,network_bias\n",
    "        # START OF FORWARD PROPAGATION FUNCTION CALLS\n",
    "        # test get_sigmoid_output \n",
    "        hidden_layer = get_sigmoid_output(input_weights, inputs[i], network_bias[0])\n",
    "        # test get_output\n",
    "        output = get_output(hidden_layer, output_weights, network_bias[1])\n",
    "        # call error function\n",
    "        error = get_error(input_y[i], output)\n",
    "        # print(\"error:\", error)\n",
    "\n",
    "        # END OF FORWARD PROPAGATION FUNCTION CALLS\n",
    "\n",
    "        # START OF BACK PROPAGATION FOR OUTPUT LAYER\n",
    "        #test function deltaErr_wrt_out\n",
    "        deltaErr_out = deltaErr_wrt_out(input_y[i], output)\n",
    "        # print(deltaErr_out)\n",
    "\n",
    "        #test function\n",
    "        deltaOut_net = deltaOut_wrt_net(output)\n",
    "        # print(deltaOut_net)\n",
    "\n",
    "        deltaErrtot_ow = deltaErr_ow(deltaErr_out, deltaOut_net, hidden_layer)\n",
    "        # print(deltaErrtot_ow)\n",
    "\n",
    "        # END OF BACK PROPAGATION FOR OUTPUT LAYER\n",
    "\n",
    "        # START BACK PROPAGATION OF HIDDEN LAYER\n",
    "        # calculate derivative of error at hidden layer\n",
    "\n",
    "        # test function deltaOut_hL\n",
    "        deltaErrOut_hL = deltaOut_hL(deltaErr_out, deltaOut_net, output_weights)\n",
    "        # print(deltaErrOut_hL)\n",
    "\n",
    "        #test function \n",
    "        deltaErrOut_netHL = deltaOut_netHL(hidden_layer)\n",
    "        # print(deltaErrOut_netHL)\n",
    "\n",
    "        deltaErrH_wi = deltaErr_wi(deltaErrOut_hL, deltaErrOut_netHL, input_weights)\n",
    "        # print(deltaErrH_wi)\n",
    "\n",
    "        # same calculation as above but with Weights matrix \n",
    "        # calculate adjusted weights using function\n",
    "        output_weights = calc_adjusted_weights(output_weights, deltaErrtot_ow)\n",
    "        input_weights = calc_adjusted_weights(input_weights, deltaErrH_wi)\n",
    "        #bias[1] = calc_adjusted_weights(bias[1], deltaErr_out)\n",
    "       # bias[0] = calc_adjusted_weights(bias[0], 0.5*np.sum(deltaErrOut_hL, dtype=np.float64))\n",
    "\n",
    "        # END OF BACK PROPAGATION OF HIDDEN LAYER\n",
    "\n",
    "    iter=iter+1\n",
    "    \n",
    "    if (iter > maxrounds):\n",
    "        break\n",
    "\n",
    "print (\"\\nFinished after \", iter, \" error =\", error, \"target=\", input_y[i], \", output=\", output, \"input final=\", inputs[i])    \n",
    "print(datetime.datetime.now())\n",
    "print (\"Weights1 adjusted:\", input_weights)\n",
    "print (\"Weights2 adjusted:\", output_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 2)\n",
      "(280,)\n",
      "(1, 2, 2)\n",
      "(1, 1, 2)\n",
      "(2, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(inputs))\n",
    "print(np.shape(input_y))\n",
    "print(np.shape(input_weights))\n",
    "print(np.shape(output_weights))\n",
    "print(np.shape(network_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reference https://pypi.python.org/pypi/python-mnist\n",
    "# https://github.com/sorki/python-mnist/blob/master/mnist/loader.py\n",
    "# TRAIN MNIST DATA\n",
    "\n",
    "mndata = MNIST('./mnist')\n",
    "images, labels = mndata.load_training()\n",
    "\n",
    "processed_images = mndata.process_images_to_numpy(images)\n",
    "# print(processed_images[0:2])\n",
    "\n",
    "target = np.array(labels)\n",
    "# print(target[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up 2 lists to filter the MNIST data into\n",
    "# keeping only 0 and 6 to classify\n",
    "# TRAIN MNIST DATA\n",
    "\n",
    "filtered_labels = []\n",
    "filtered_images = []\n",
    "for i in range(len(target)):\n",
    "    if target[i]==0 or target[i]==6:\n",
    "        filtered_labels.append(target[i])\n",
    "        filtered_images.append(processed_images[i])\n",
    "        \n",
    "# remap the value 6 to 1, so classification is binary\n",
    "\n",
    "#print(filtered_labels[0:10])\n",
    "\n",
    "for i in range(len(filtered_labels)):\n",
    "    if filtered_labels[i]==6:\n",
    "        filtered_labels[i]=1\n",
    "\n",
    "#print(filtered_labels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert the lists to arrays\n",
    "# TRAIN MNIST DATA\n",
    "filtered_labels = np.array(filtered_labels)\n",
    "\n",
    "filtered_images = np.array(filtered_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST TEST DATA\n",
    "test_images, test_labels = mndata.load_testing()\n",
    "\n",
    "test_images = mndata.process_images_to_numpy(test_images)\n",
    "#print(processed_images[0:2])\n",
    "\n",
    "test_target = np.array(test_labels)\n",
    "\n",
    "# set up 2 lists to filter the MNIST data into\n",
    "# keeping only 0 and 6 to classify\n",
    "# TEST MNIST DATA\n",
    "\n",
    "filtered_test_labels = []\n",
    "filtered_test_images = []\n",
    "for i in range(len(target)):\n",
    "    if target[i]==0 or target[i]==6:\n",
    "        filtered_test_labels.append(target[i])\n",
    "        filtered_test_images.append(processed_images[i])\n",
    "        \n",
    "# remap the value 6 to 1, so classification is binary\n",
    "\n",
    "#print(filtered_labels[0:10])\n",
    "\n",
    "for i in range(len(filtered_test_labels)):\n",
    "    if filtered_test_labels[i]==6:\n",
    "        filtered_test_labels[i]=1\n",
    "        \n",
    "# convert the lists to arrays\n",
    "# TEST MNIST DATA\n",
    "filtered_test_labels = np.array(filtered_test_labels)\n",
    "\n",
    "filtered_test_images = np.array(filtered_test_images)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(filtered_test_labels[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: samples = 11841 , attribs = 784\n",
      "Length of inputs 11841\n",
      "input Weights 784\n",
      "output Weights 1\n",
      "Network Bias 2\n"
     ]
    }
   ],
   "source": [
    "# set up weights and biases for MNIST data, get nattribs value\n",
    "# TRAIN MNIST DATA\n",
    "\n",
    "(train_samples, train_shape) = np.shape(filtered_images)\n",
    "print (\"train: samples =\", train_samples, \", attribs =\", train_shape)\n",
    "\n",
    "# Test weights and bias initialisation based on network inputs, hidden layers, and outputs\n",
    "# first line of moons.csv\n",
    "#input_X =[[2.07106946, 0.41152931]]\n",
    "\n",
    "#(nsamples, nattribs) = np.shape(input_X)\n",
    "n_inputs = train_shape\n",
    "n_hidden_layer = 1\n",
    "n_hidden_inputs = 2\n",
    "n_outputs = 1\n",
    "\n",
    "# normalise training data\n",
    "# rescale the inputs using normalization \n",
    "mnist_train = preprocessing.normalize(filtered_images)\n",
    "#print(\"normalised inputs\",inputs)\n",
    "\n",
    "input_weights = np.array(initialise_input_weights(n_inputs, n_hidden_inputs))\n",
    "output_weights = np.array(initialise_output_weights(n_hidden_inputs, n_outputs))\n",
    "#network_weights = initialise_weights(n_inputs, n_hidden_inputs, n_outputs)\n",
    "network_bias = np.array(initialise_bias(n_hidden_layer))\n",
    "\n",
    "print(\"Length of inputs\",len(filtered_images))\n",
    "#print(\"actual y\",input_y)\n",
    "print(\"input Weights\", len(input_weights))\n",
    "print(\"output Weights\", len(output_weights))\n",
    "print(\"Network Bias\", len(network_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "120\n",
      "Index:  0  Input:  [ 0.83369257  0.55222885]\n",
      "Index:  0  Target value:  0\n",
      "Index:  1  Input:  [-0.54077318 -0.84116846]\n",
      "Index:  1  Target value:  1\n",
      "Index:  2  Input:  [ 0.99991817 -0.0127925 ]\n",
      "Index:  2  Target value:  1\n",
      "Index:  3  Input:  [ 0.13858785  0.99035014]\n",
      "Index:  3  Target value:  1\n",
      "Index:  4  Input:  [ 0.75767119 -0.65263648]\n",
      "Index:  4  Target value:  1\n",
      "Index:  5  Input:  [ 0.95154886  0.3074976 ]\n",
      "Index:  5  Target value:  1\n",
      "Index:  6  Input:  [-0.99655695  0.08291103]\n",
      "Index:  6  Target value:  0\n",
      "Index:  7  Input:  [ 0.99452772 -0.10447307]\n",
      "Index:  7  Target value:  1\n",
      "Index:  8  Input:  [ 0.99969382  0.02474393]\n",
      "Index:  8  Target value:  1\n",
      "Index:  9  Input:  [ 0.89158845 -0.45284659]\n",
      "Index:  9  Target value:  1\n",
      "Index:  10  Input:  [-0.90891162  0.41698882]\n",
      "Index:  10  Target value:  0\n",
      "Index:  11  Input:  [ 0.99936025  0.03576434]\n",
      "Index:  11  Target value:  1\n",
      "Index:  12  Input:  [ 0.05859329  0.99828194]\n",
      "Index:  12  Target value:  0\n",
      "Index:  13  Input:  [ 0.97561738 -0.21947831]\n",
      "Index:  13  Target value:  1\n",
      "Index:  14  Input:  [-0.58515302  0.81092289]\n",
      "Index:  14  Target value:  0\n",
      "Index:  15  Input:  [ 0.73715419  0.67572458]\n",
      "Index:  15  Target value:  0\n",
      "Index:  16  Input:  [ 0.98411788 -0.17751619]\n",
      "Index:  16  Target value:  1\n",
      "Index:  17  Input:  [ 0.7285953  -0.68494444]\n",
      "Index:  17  Target value:  1\n",
      "Index:  18  Input:  [ 0.17876266  0.98389223]\n",
      "Index:  18  Target value:  0\n",
      "Index:  19  Input:  [-0.49609224  0.86826983]\n",
      "Index:  19  Target value:  0\n",
      "Index:  20  Input:  [ 0.8177076 -0.5756338]\n",
      "Index:  20  Target value:  1\n",
      "Index:  21  Input:  [ 0.90763117 -0.41976858]\n",
      "Index:  21  Target value:  1\n",
      "Index:  22  Input:  [ 0.96764182 -0.25232779]\n",
      "Index:  22  Target value:  1\n",
      "Index:  23  Input:  [ 0.85336302 -0.52131713]\n",
      "Index:  23  Target value:  1\n",
      "Index:  24  Input:  [ 0.0056916  0.9999838]\n",
      "Index:  24  Target value:  0\n",
      "Index:  25  Input:  [ 0.9314557  -0.36385476]\n",
      "Index:  25  Target value:  1\n",
      "Index:  26  Input:  [ 0.95596079 -0.2934944 ]\n",
      "Index:  26  Target value:  1\n",
      "Index:  27  Input:  [ 0.93519672 -0.35412865]\n",
      "Index:  27  Target value:  1\n",
      "Index:  28  Input:  [-0.81578278  0.57835841]\n",
      "Index:  28  Target value:  0\n",
      "Index:  29  Input:  [ 0.56477223  0.82524683]\n",
      "Index:  29  Target value:  0\n",
      "Index:  30  Input:  [-0.98718141  0.15960219]\n",
      "Index:  30  Target value:  0\n",
      "Index:  31  Input:  [ 0.9939639  -0.10970768]\n",
      "Index:  31  Target value:  1\n",
      "Index:  32  Input:  [ 0.9294835  0.3688637]\n",
      "Index:  32  Target value:  0\n",
      "Index:  33  Input:  [ 0.99528031 -0.09704181]\n",
      "Index:  33  Target value:  1\n",
      "Index:  34  Input:  [-0.94750067  0.31975379]\n",
      "Index:  34  Target value:  0\n",
      "Index:  35  Input:  [ 0.93377117  0.35787065]\n",
      "Index:  35  Target value:  0\n",
      "Index:  36  Input:  [-0.82807313  0.5606201 ]\n",
      "Index:  36  Target value:  0\n",
      "Index:  37  Input:  [-0.02790785  0.9996105 ]\n",
      "Index:  37  Target value:  0\n",
      "Index:  38  Input:  [ 0.33907863 -0.94075804]\n",
      "Index:  38  Target value:  1\n",
      "Index:  39  Input:  [ 0.98908998 -0.1473126 ]\n",
      "Index:  39  Target value:  1\n",
      "Index:  40  Input:  [ 0.86706447 -0.49819595]\n",
      "Index:  40  Target value:  1\n",
      "Index:  41  Input:  [ 0.66275502 -0.74883629]\n",
      "Index:  41  Target value:  1\n",
      "Index:  42  Input:  [-0.96658814  0.25633448]\n",
      "Index:  42  Target value:  0\n",
      "Index:  43  Input:  [ 0.90700922 -0.42111077]\n",
      "Index:  43  Target value:  1\n",
      "Index:  44  Input:  [-0.34258757  0.9394859 ]\n",
      "Index:  44  Target value:  0\n",
      "Index:  45  Input:  [ 0.91769328 -0.39728963]\n",
      "Index:  45  Target value:  1\n",
      "Index:  46  Input:  [ 0.08259033  0.99658358]\n",
      "Index:  46  Target value:  1\n",
      "Index:  47  Input:  [ 0.98586709 -0.16752934]\n",
      "Index:  47  Target value:  1\n",
      "Index:  48  Input:  [ 0.37294378  0.92785394]\n",
      "Index:  48  Target value:  1\n",
      "Index:  49  Input:  [-0.99948036 -0.03223381]\n",
      "Index:  49  Target value:  0\n",
      "Index:  50  Input:  [-0.35075123  0.93646867]\n",
      "Index:  50  Target value:  0\n",
      "Index:  51  Input:  [-0.30455074  0.95249612]\n",
      "Index:  51  Target value:  0\n",
      "Index:  52  Input:  [ 0.16460503  0.98635956]\n",
      "Index:  52  Target value:  0\n",
      "Index:  53  Input:  [ 0.79635695  0.60482692]\n",
      "Index:  53  Target value:  0\n",
      "Index:  54  Input:  [ 0.44749677  0.89428555]\n",
      "Index:  54  Target value:  0\n",
      "Index:  55  Input:  [-0.72962975  0.6838424 ]\n",
      "Index:  55  Target value:  0\n",
      "Index:  56  Input:  [-0.02489755  0.99969001]\n",
      "Index:  56  Target value:  1\n",
      "Index:  57  Input:  [-0.18478485  0.982779  ]\n",
      "Index:  57  Target value:  0\n",
      "Index:  58  Input:  [-0.89819962  0.43958782]\n",
      "Index:  58  Target value:  0\n",
      "Index:  59  Input:  [ 0.44130994  0.89735475]\n",
      "Index:  59  Target value:  0\n",
      "Index:  60  Input:  [ 0.99967783  0.02538168]\n",
      "Index:  60  Target value:  1\n",
      "Index:  61  Input:  [-0.89913696  0.43766738]\n",
      "Index:  61  Target value:  0\n",
      "Index:  62  Input:  [ 0.76172684  0.64789832]\n",
      "Index:  62  Target value:  0\n",
      "Index:  63  Input:  [ 0.92503294 -0.37988689]\n",
      "Index:  63  Target value:  1\n",
      "Index:  64  Input:  [ 0.49265341  0.87022561]\n",
      "Index:  64  Target value:  0\n",
      "Index:  65  Input:  [ 0.99813018 -0.06112403]\n",
      "Index:  65  Target value:  1\n",
      "Index:  66  Input:  [ 0.99219145 -0.1247242 ]\n",
      "Index:  66  Target value:  1\n",
      "Index:  67  Input:  [ 0.74305834 -0.66922665]\n",
      "Index:  67  Target value:  1\n",
      "Index:  68  Input:  [-0.96651561  0.25660784]\n",
      "Index:  68  Target value:  0\n",
      "Index:  69  Input:  [-0.40959469  0.91226761]\n",
      "Index:  69  Target value:  0\n",
      "Index:  70  Input:  [ 0.7269864  -0.68665186]\n",
      "Index:  70  Target value:  1\n",
      "Index:  71  Input:  [ 0.99547416 -0.09503259]\n",
      "Index:  71  Target value:  1\n",
      "Index:  72  Input:  [ 0.82624189  0.56331548]\n",
      "Index:  72  Target value:  0\n",
      "Index:  73  Input:  [ 0.6696561   0.74267133]\n",
      "Index:  73  Target value:  1\n",
      "Index:  74  Input:  [ 0.16495897  0.98630043]\n",
      "Index:  74  Target value:  1\n",
      "Index:  75  Input:  [ 0.16102606  0.98695015]\n",
      "Index:  75  Target value:  0\n",
      "Index:  76  Input:  [ 0.8653167  -0.50122551]\n",
      "Index:  76  Target value:  1\n",
      "Index:  77  Input:  [ 0.99892428 -0.04637117]\n",
      "Index:  77  Target value:  1\n",
      "Index:  78  Input:  [ 0.99976134  0.02184614]\n",
      "Index:  78  Target value:  1\n",
      "Index:  79  Input:  [ 0.99947654 -0.03235187]\n",
      "Index:  79  Target value:  0\n",
      "Index:  80  Input:  [ 0.02706176  0.99963376]\n",
      "Index:  80  Target value:  0\n",
      "Index:  81  Input:  [ 0.98278306 -0.18476327]\n",
      "Index:  81  Target value:  1\n",
      "Index:  82  Input:  [-0.99953495  0.03049414]\n",
      "Index:  82  Target value:  0\n",
      "Index:  83  Input:  [ 0.85584833 -0.51722688]\n",
      "Index:  83  Target value:  1\n",
      "Index:  84  Input:  [ 0.98381048  0.17921197]\n",
      "Index:  84  Target value:  1\n",
      "Index:  85  Input:  [-0.78861684  0.61488493]\n",
      "Index:  85  Target value:  0\n",
      "Index:  86  Input:  [ 0.66817981 -0.74399982]\n",
      "Index:  86  Target value:  1\n",
      "Index:  87  Input:  [ 0.99261748  0.12128703]\n",
      "Index:  87  Target value:  0\n",
      "Index:  88  Input:  [-0.57036687  0.82139006]\n",
      "Index:  88  Target value:  0\n",
      "Index:  89  Input:  [ 0.89343425 -0.44919398]\n",
      "Index:  89  Target value:  1\n",
      "Index:  90  Input:  [ 0.95607851 -0.29311069]\n",
      "Index:  90  Target value:  1\n",
      "Index:  91  Input:  [ 0.93911299 -0.34360848]\n",
      "Index:  91  Target value:  1\n",
      "Index:  92  Input:  [ 0.99784625  0.06559614]\n",
      "Index:  92  Target value:  0\n",
      "Index:  93  Input:  [ 0.92876325  0.37067348]\n",
      "Index:  93  Target value:  0\n",
      "Index:  94  Input:  [ 0.90075589 -0.43432571]\n",
      "Index:  94  Target value:  1\n",
      "Index:  95  Input:  [ 0.94871775 -0.31612438]\n",
      "Index:  95  Target value:  1\n",
      "Index:  96  Input:  [ 0.96651498  0.25661019]\n",
      "Index:  96  Target value:  1\n",
      "Index:  97  Input:  [ 0.18905394  0.9819667 ]\n",
      "Index:  97  Target value:  0\n",
      "Index:  98  Input:  [ 0.37298071  0.9278391 ]\n",
      "Index:  98  Target value:  0\n",
      "Index:  99  Input:  [ 0.00611542  0.9999813 ]\n",
      "Index:  99  Target value:  0\n",
      "Index:  100  Input:  [-0.47499365  0.87998922]\n",
      "Index:  100  Target value:  0\n",
      "Index:  101  Input:  [ 0.93935026  0.3429593 ]\n",
      "Index:  101  Target value:  0\n",
      "Index:  102  Input:  [ 0.99988059 -0.01545362]\n",
      "Index:  102  Target value:  1\n",
      "Index:  103  Input:  [  9.99999613e-01   8.80270368e-04]\n",
      "Index:  103  Target value:  1\n",
      "Index:  104  Input:  [ 0.49150491  0.87087481]\n",
      "Index:  104  Target value:  0\n",
      "Index:  105  Input:  [ 0.68226451  0.73110542]\n",
      "Index:  105  Target value:  0\n",
      "Index:  106  Input:  [-0.88706775  0.46163926]\n",
      "Index:  106  Target value:  0\n",
      "Index:  107  Input:  [ 0.28864432  0.9574364 ]\n",
      "Index:  107  Target value:  0\n",
      "Index:  108  Input:  [ 0.99989455  0.01452212]\n",
      "Index:  108  Target value:  0\n",
      "Index:  109  Input:  [ 0.91372597 -0.40633097]\n",
      "Index:  109  Target value:  1\n",
      "Index:  110  Input:  [ 0.9754861   0.22006105]\n",
      "Index:  110  Target value:  1\n",
      "Index:  111  Input:  [ 0.79265546  0.60966985]\n",
      "Index:  111  Target value:  0\n",
      "Index:  112  Input:  [-0.33066687  0.94374754]\n",
      "Index:  112  Target value:  0\n",
      "Index:  113  Input:  [-0.77970018  0.62615304]\n",
      "Index:  113  Target value:  0\n",
      "Index:  114  Input:  [ 0.48120095  0.87661032]\n",
      "Index:  114  Target value:  0\n",
      "Index:  115  Input:  [ 0.30681998  0.95176757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  115  Target value:  1\n",
      "Index:  116  Input:  [ 0.95242449  0.30477464]\n",
      "Index:  116  Target value:  0\n",
      "Index:  117  Input:  [ 0.96201311 -0.27300325]\n",
      "Index:  117  Target value:  1\n",
      "Index:  118  Input:  [ 0.99508722  0.09900215]\n",
      "Index:  118  Target value:  1\n",
      "Index:  119  Input:  [-0.17222527  0.98505759]\n",
      "Index:  119  Target value:  0\n"
     ]
    }
   ],
   "source": [
    "## TEST MODEL\n",
    "inputs = preprocessing.normalize(test_X)\n",
    "target = test_y\n",
    "target = np.array(target)\n",
    "print(len(inputs))\n",
    "print(len(target))\n",
    "#tol=1e-7\n",
    "#maxrounds=1000\n",
    "#iter=0\n",
    "error = 99.0\n",
    "#while abs(error) > tol:\n",
    "error_res = []\n",
    "result = []\n",
    "#result = np.array(result)\n",
    "\n",
    "for i in range(len(inputs)):\n",
    "    print (\"Index: \",i, \" Input: \", inputs[i])\n",
    "    print (\"Index: \",i,\" Target value: \", target[i])\n",
    "        \n",
    "    ### START OF FORWARD PROPAGATION FUNCTION CALLS\n",
    "    # test get_sigmoid_output \n",
    "    hidden_layer = get_sigmoid_output(input_weights, inputs[i], network_bias[0])\n",
    "    ##print (\"hidden_layer result:\", hidden_layer)\n",
    "        \n",
    "    # test get_output\n",
    "    output = get_output(hidden_layer, output_weights, network_bias[1])\n",
    "    #  print (\"output:\", output)\n",
    "    result.append(output)\n",
    "        \n",
    "    # call error function\n",
    "    error = get_error(target[i], output)\n",
    "    error_res.append(error)\n",
    "    #print(\"error:\", error)\n",
    "        \n",
    "    # END OF FORWARD PROPAGATION FUNCTION CALLS\n",
    "result = np.array(result)  \n",
    "error_res = np.array(error_res)\n",
    "target = np.array(target)\n",
    "#print(\"Target:\", target)        \n",
    "#print(\"Results: \", result)\n",
    "#print(\"Error:\", error_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "120\n",
      "1e-07\n",
      "True Negative:  0  -  [[  2.87856318e-99]]\n",
      "False Positive:  1  -  [[  2.76486326e-99]]\n",
      "False Positive:  1  -  [[  2.86357620e-99]]\n",
      "False Positive:  1  -  [[  2.86407842e-99]]\n",
      "False Positive:  1  -  [[  2.82778111e-99]]\n",
      "False Positive:  1  -  [[  2.87415724e-99]]\n",
      "True Negative:  0  -  [[  2.77930508e-99]]\n",
      "False Positive:  1  -  [[  2.85969545e-99]]\n",
      "False Positive:  1  -  [[  2.86505872e-99]]\n",
      "False Positive:  1  -  [[  2.84141278e-99]]\n",
      "True Negative:  0  -  [[  2.79547977e-99]]\n",
      "False Positive:  1  -  [[  2.86548219e-99]]\n",
      "True Negative:  0  -  [[  2.86073621e-99]]\n",
      "False Positive:  1  -  [[  2.85430143e-99]]\n",
      "True Negative:  0  -  [[  2.82453612e-99]]\n",
      "True Negative:  0  -  [[  2.87907008e-99]]\n",
      "False Positive:  1  -  [[  2.85633838e-99]]\n",
      "False Positive:  1  -  [[  2.82526763e-99]]\n",
      "True Negative:  0  -  [[  2.86566240e-99]]\n",
      "True Negative:  0  -  [[  2.83068644e-99]]\n",
      "False Positive:  1  -  [[  2.83338605e-99]]\n",
      "False Positive:  1  -  [[  2.84341376e-99]]\n",
      "False Positive:  1  -  [[  2.85265034e-99]]\n",
      "False Positive:  1  -  [[  2.83706087e-99]]\n",
      "True Negative:  0  -  [[  2.85839160e-99]]\n",
      "False Positive:  1  -  [[  2.84665789e-99]]\n",
      "False Positive:  1  -  [[  2.85050942e-99]]\n",
      "False Positive:  1  -  [[  2.84720523e-99]]\n",
      "True Negative:  0  -  [[  2.80557925e-99]]\n",
      "True Negative:  0  -  [[  2.87710499e-99]]\n",
      "True Negative:  0  -  [[  2.78253946e-99]]\n",
      "False Positive:  1  -  [[  2.85946273e-99]]\n",
      "True Negative:  0  -  [[  2.87560650e-99]]\n",
      "False Positive:  1  -  [[  2.86002374e-99]]\n",
      "True Negative:  0  -  [[  2.79018704e-99]]\n",
      "True Negative:  0  -  [[  2.87536221e-99]]\n",
      "True Negative:  0  -  [[  2.80437576e-99]]\n",
      "True Negative:  0  -  [[  2.85684773e-99]]\n",
      "False Positive:  1  -  [[  2.79869847e-99]]\n",
      "False Positive:  1  -  [[  2.85775533e-99]]\n",
      "False Positive:  1  -  [[  2.83856358e-99]]\n",
      "False Positive:  1  -  [[  2.81994951e-99]]\n",
      "True Negative:  0  -  [[  2.78700806e-99]]\n",
      "False Positive:  1  -  [[  2.84333378e-99]]\n",
      "True Negative:  0  -  [[  2.84029047e-99]]\n",
      "False Positive:  1  -  [[  2.84473833e-99]]\n",
      "False Positive:  1  -  [[  2.86176473e-99]]\n",
      "False Positive:  1  -  [[  2.85681142e-99]]\n",
      "False Positive:  1  -  [[  2.87235641e-99]]\n",
      "True Negative:  0  -  [[  2.77494022e-99]]\n",
      "True Negative:  0  -  [[  2.83980758e-99]]\n",
      "True Negative:  0  -  [[  2.84250231e-99]]\n",
      "True Negative:  0  -  [[  2.86511156e-99]]\n",
      "True Negative:  0  -  [[  2.87895481e-99]]\n",
      "True Negative:  0  -  [[  2.87445320e-99]]\n",
      "True Negative:  0  -  [[  2.81333248e-99]]\n",
      "False Positive:  1  -  [[  2.85698778e-99]]\n",
      "True Negative:  0  -  [[  2.84907702e-99]]\n",
      "True Negative:  0  -  [[  2.79678849e-99]]\n",
      "True Negative:  0  -  [[  2.87429044e-99]]\n",
      "False Positive:  1  -  [[  2.86508337e-99]]\n",
      "True Negative:  0  -  [[  2.79667606e-99]]\n",
      "True Negative:  0  -  [[  2.87908698e-99]]\n",
      "False Positive:  1  -  [[  2.84574488e-99]]\n",
      "True Negative:  0  -  [[  2.87557513e-99]]\n",
      "False Positive:  1  -  [[  2.86157630e-99]]\n",
      "False Positive:  1  -  [[  2.85878844e-99]]\n",
      "False Positive:  1  -  [[  2.82650366e-99]]\n",
      "True Negative:  0  -  [[  2.78702132e-99]]\n",
      "True Negative:  0  -  [[  2.83623802e-99]]\n",
      "False Positive:  1  -  [[  2.82513179e-99]]\n",
      "False Positive:  1  -  [[  2.86011209e-99]]\n",
      "True Negative:  0  -  [[  2.87866518e-99]]\n",
      "False Positive:  1  -  [[  2.87863983e-99]]\n",
      "False Positive:  1  -  [[  2.86512543e-99]]\n",
      "True Negative:  0  -  [[  2.86497103e-99]]\n",
      "False Positive:  1  -  [[  2.83836866e-99]]\n",
      "False Positive:  1  -  [[  2.86219760e-99]]\n",
      "False Positive:  1  -  [[  2.86494647e-99]]\n",
      "True Negative:  0  -  [[  2.86277918e-99]]\n",
      "True Negative:  0  -  [[  2.85935146e-99]]\n",
      "False Positive:  1  -  [[  2.85599230e-99]]\n",
      "True Negative:  0  -  [[  2.77724576e-99]]\n",
      "False Positive:  1  -  [[  2.83732927e-99]]\n",
      "False Positive:  1  -  [[  2.87049692e-99]]\n",
      "True Negative:  0  -  [[  2.80814218e-99]]\n",
      "False Positive:  1  -  [[  2.82037046e-99]]\n",
      "True Negative:  0  -  [[  2.86858460e-99]]\n",
      "True Negative:  0  -  [[  2.82559129e-99]]\n",
      "False Positive:  1  -  [[  2.84163684e-99]]\n",
      "False Positive:  1  -  [[  2.85052975e-99]]\n",
      "False Positive:  1  -  [[  2.84779177e-99]]\n",
      "True Negative:  0  -  [[  2.86660153e-99]]\n",
      "True Negative:  0  -  [[  2.87564606e-99]]\n",
      "False Positive:  1  -  [[  2.84254090e-99]]\n",
      "False Positive:  1  -  [[  2.84929765e-99]]\n",
      "False Positive:  1  -  [[  2.87280353e-99]]\n",
      "True Negative:  0  -  [[  2.86605773e-99]]\n",
      "True Negative:  0  -  [[  2.87235752e-99]]\n",
      "True Negative:  0  -  [[  2.85841080e-99]]\n",
      "True Negative:  0  -  [[  2.83207622e-99]]\n",
      "True Negative:  0  -  [[  2.87501999e-99]]\n",
      "False Positive:  1  -  [[  2.86346875e-99]]\n",
      "False Positive:  1  -  [[  2.86412338e-99]]\n",
      "True Negative:  0  -  [[  2.87554808e-99]]\n",
      "True Negative:  0  -  [[  2.87875818e-99]]\n",
      "True Negative:  0  -  [[  2.79809624e-99]]\n",
      "True Negative:  0  -  [[  2.86965529e-99]]\n",
      "True Negative:  0  -  [[  2.86466114e-99]]\n",
      "False Positive:  1  -  [[  2.84420892e-99]]\n",
      "False Positive:  1  -  [[  2.87175059e-99]]\n",
      "True Negative:  0  -  [[  2.87897861e-99]]\n",
      "True Negative:  0  -  [[  2.84099035e-99]]\n",
      "True Negative:  0  -  [[  2.80895729e-99]]\n",
      "True Negative:  0  -  [[  2.87530186e-99]]\n",
      "False Positive:  1  -  [[  2.87026549e-99]]\n",
      "True Negative:  0  -  [[  2.87408821e-99]]\n",
      "False Positive:  1  -  [[  2.85158520e-99]]\n",
      "False Positive:  1  -  [[  2.86780785e-99]]\n",
      "True Negative:  0  -  [[  2.84973360e-99]]\n",
      "True Positive:  0\n",
      "True Negative:  60\n",
      "False Positive:  60\n",
      "False Negative:  0\n"
     ]
    }
   ],
   "source": [
    "# calculate the accuracy of the NN\n",
    "tol=1e-7\n",
    "print(len(target))\n",
    "print(len(result))\n",
    "print(tol)\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "for i in range(len(target)):\n",
    "        \n",
    "        if (target[i] == 1 and target[i]-result[i] <= tol):\n",
    "            TP = TP + 1\n",
    "            print(\"True Positive: \", target[i], \" - \", result[i])\n",
    "\n",
    "        if (target[i] == 0 and target[i]-result[i] <= tol):\n",
    "            TN = TN + 1\n",
    "            print(\"True Negative: \",target[i], \" - \", result[i])\n",
    "            \n",
    "        if (target[i] == 1 and target[i]-result[i] > tol):\n",
    "            FP = FP + 1\n",
    "            print(\"False Positive: \",target[i], \" - \", result[i])\n",
    "            \n",
    "        if (target[i] == 0 and target[i]-result[i] > tol):\n",
    "            FN = FN + 1\n",
    "            print(\"False Negative: \",target[i], \" - \", result[i])\n",
    "        \n",
    "print(\"True Positive: \", TP)\n",
    "print(\"True Negative: \", TN)\n",
    "print(\"False Positive: \", FP)\n",
    "print(\"False Negative: \", FN)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
